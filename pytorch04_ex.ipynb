{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPa879ki5eKDmzvKszGm67U",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lanehale/airline-chatbot/blob/main/pytorch04_ex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XbWhW4U8Yuut"
      },
      "outputs": [],
      "source": [
        "# 1. Our models are underperforming (not fitting the data well). What are 3 methods for preventing underfitting?\n",
        "# - Increase dataset size - provide more images\n",
        "# - Data Augmentation - transform existing data (rotate, flip, crop), making it more diverse\n",
        "# - Increase model complexity - add layers (or neurons)\n",
        "# - Increase training duration - add epochs\n",
        "# - Try different optimizers - Adam, SGD, etc.\n",
        "\n",
        "# check for GPU\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "print (torch.__version__)  # we need version >= 1.10.0\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device"
      ],
      "metadata": {
        "id": "aLNLptU7ZMLl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Increase dataset size\n",
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to datafile\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"pizza_steak_sushi_20_percent\"\n",
        "\n",
        "# If the image folder doesn't exist, download and prepare it\n",
        "if image_path.is_dir():\n",
        "  print(f\"{image_path} directory exists\")\n",
        "else:\n",
        "  print(f\"{image_path} directory not found, creating one...\")\n",
        "  image_path.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Download images\n",
        "with open(data_path / \"pizza_steak_sushi_20_percent.zip\", \"wb\") as f:\n",
        "  request = requests.get(\"https://github.com/mrdbourke/pytorch-deep-learning/raw/main/data/pizza_steak_sushi_20_percent.zip\")\n",
        "  print(\"Downloading pizza, steak, sushi 20% data...\")\n",
        "  f.write(request.content)\n",
        "\n",
        "# Unzip data\n",
        "with zipfile.ZipFile(data_path / \"pizza_steak_sushi_20_percent.zip\", \"r\") as zip_ref:  # note capital F in .ZipFile\n",
        "  print(\"Unzipping pizza, steak, sushi 20% data...\")\n",
        "  zip_ref.extractall(image_path)"
      ],
      "metadata": {
        "id": "T81GUDxWeQ3Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# see how many images we have\n",
        "import os\n",
        "\n",
        "def walk_through_dir(dir_path):\n",
        "  for dirpath, dirnames, filenames in os.walk(dir_path):\n",
        "    print(f\"There are {len(dirnames)} directories and {len(filenames)} images in '{dirpath}'\")\n",
        "\n",
        "walk_through_dir(image_path)"
      ],
      "metadata": {
        "id": "J_KeMkgjjkV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls data/pizza_steak_sushi_20_percent/train\n",
        "!ls data/pizza_steak_sushi_20_percent/test"
      ],
      "metadata": {
        "id": "h0xyVtdE15vh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and test paths\n",
        "train_data_20_path = image_path / \"train\"\n",
        "test_data_20_path = image_path / \"test\"\n",
        "\n",
        "train_data_20_path, test_data_20_path"
      ],
      "metadata": {
        "id": "TtVWfiLC5M4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn 20 percent datapaths into Datasets and DataLoaders\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "simple_transform = transforms.Compose([  # use this for test datasets\n",
        "    # Resize the images to 224x224\n",
        "    transforms.Resize((224,224)),#64,64)),\n",
        "    # Turn the image into a torch.Tensor\n",
        "    transforms.ToTensor()  # this also converts all pixel values from 0 to 255 to be between 0.0 and 1.0\n",
        "])\n",
        "\n",
        "data_20_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),#64,64)),\n",
        "    # Flip images randomly on the horizontal\n",
        "    transforms.RandomHorizontalFlip(p=0.5),  # p = probability of flip, 0.5 = 50% chance\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "ml4fN3wZ58zW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Write a function to see transforms on various images\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "\n",
        "\"\"\"Plots a series of random images from image_paths.\n",
        "\n",
        "Will open n image paths from image_paths, transform them\n",
        "with transform and plot them side by side.\n",
        "\n",
        "Args:\n",
        "    image_paths (list): List of target image paths.\n",
        "    transform (PyTorch Transforms): Transforms to apply to images.\n",
        "    n (int, optional): Number of images to plot. Defaults to 3.\n",
        "    seed (int, optional): Random seed for the random generator. Defaults to 14.\n",
        "\"\"\"\n",
        "def plot_transformed_images(image_paths, transform, n=3, seed=14):\n",
        "  random.seed(seed)\n",
        "  random_image_paths = random.sample(image_paths, k=n)\n",
        "  for image_path in random_image_paths:\n",
        "    with Image.open(image_path) as f:\n",
        "      fig, ax = plt.subplots(1,2)\n",
        "      ax[0].imshow(f)\n",
        "      ax[1].set_title(f\"Orginal \\nSize: {f.size}\")\n",
        "\n",
        "      # Transform and plot image\n",
        "      # Note: permute() will change shape of image to suit matplotlib\n",
        "      # (PyTorch default is [C, H, W] but Matplotlib is [H, W, C])\n",
        "      transformed_image = transform(f).permute(1,2,0)\n",
        "      ax[1].imshow(transformed_image)\n",
        "      ax[1].set_title(f\"Transformed \\Size: {transformed_image.shape}\")\n",
        "      ax[1].axis(\"off\")\n",
        "\n",
        "plot_transformed_images(image_paths=image_path_list,\n",
        "                        transform=data_20_transform,\n",
        "                        n=3)"
      ],
      "metadata": {
        "id": "VTKXDqFkAz5a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create datasets\n",
        "from torchvision import datasets\n",
        "train_data_20 = datasets.ImageFolder(root=train_data_20_path,      # train/ folder images\n",
        "                                     transform=data_20_transform,  # transformed data\n",
        "                                     target_transform=None)        # no label transforms needed\n",
        "test_data_20 = datasets.ImageFolder(root=test_data_20_path,\n",
        "                                    transform=data_20_transform)\n",
        "train_data_20, test_data_20"
      ],
      "metadata": {
        "id": "B4M6iKNwSmud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Inspect the datasets\n",
        "class_names = train_data_20.classes\n",
        "class_dict = train_data_20.class_to_idx\n",
        "class_names, class_dict"
      ],
      "metadata": {
        "id": "8vlJvi5dUI5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn train and test datasets into DataLoaders (making them iterable)\n",
        "from torch.utils.data import DataLoader\n",
        "train_dataloader = DataLoader(dataset=train_data_20,\n",
        "                              batch_size=1,   # of samples per batch\n",
        "                              num_workers=1,  # of subprocesses to use for data loading\n",
        "                              shuffle=True)   # shuffle the data\n",
        "test_dataloader = DataLoader(dataset=test_data_20,\n",
        "                             batch_size=1,\n",
        "                             num_workers=1,\n",
        "                             shuffle=False)   # don't usually need to shuffle test data\n",
        "train_dataloader, test_dataloader"
      ],
      "metadata": {
        "id": "_pxYuLgAVfha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size is currently 1\n",
        "img, label = next(iter(train_dataloader))\n",
        "img.shape, label.shape"
      ],
      "metadata": {
        "id": "1eziiH50Wmtd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TinyVGG class\n",
        "class TinyVGG(nn.Module):\n",
        "  \"\"\"\n",
        "  Model architecture copying TinyVGG from:\n",
        "  https://poloclub.github.io/cnn-explainer/\n",
        "  \"\"\"\n",
        "  def __init__(self, input_shape: int, hidden_units: int, output_shape: int) -> None:\n",
        "    super().__init__()\n",
        "    self.conv_block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,  # size of square going over image\n",
        "                  stride=1,       # default\n",
        "                  padding=1),     # options = \"valid\" (no padding) or \"same\" (output has same shape as input) or int for specific number\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units,\n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size=3,\n",
        "                  stride=1,\n",
        "                  padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)  # default stride = kernel_size\n",
        "    )\n",
        "    self.conv_block_2 = nn.Sequential(\n",
        "        nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(hidden_units, hidden_units, kernel_size=3, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*56*56, #*16*16,  # in_features shape from each layer compressing, changing shape of input data\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x: torch.Tensor):\n",
        "    x = self.conv_block_1(x)\n",
        "    x = self.conv_block_2(x)\n",
        "    x = self.classifier(x)\n",
        "    return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model_20 = TinyVGG(input_shape=3,\n",
        "                   hidden_units=10,\n",
        "                   output_shape=len(train_data_20.classes)).to(device)\n",
        "model_20"
      ],
      "metadata": {
        "id": "mYkKq9MlW4qT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_step function\n",
        "def train_step(model: torch.nn.Module,\n",
        "               dataloader: torch.utils.data.DataLoader,\n",
        "               loss_fn: torch.nn.Module,\n",
        "               optimizer: torch.optim.Optimizer):\n",
        "\n",
        "  # Put model in train mode\n",
        "  model.train()\n",
        "\n",
        "  # Set up loss and accuracy values\n",
        "  train_loss, train_acc = 0, 0\n",
        "\n",
        "  # Loop through data batches\n",
        "  for batch, (X, y) in enumerate(dataloader):\n",
        "    # Send data to target device\n",
        "    X, y = X.to(device), y.to(device)\n",
        "\n",
        "    # 1. Forward pass\n",
        "    y_pred = model(X)\n",
        "\n",
        "    # 2. Calculate and accumulate loss\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss.item()\n",
        "\n",
        "    # 3. Optimizer zero grad\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # 4. Loss backward\n",
        "    loss.backward()\n",
        "\n",
        "    # 5. Optimizer step\n",
        "    optimizer.step()\n",
        "\n",
        "    # Calculate and accumulate accuracy metrics across all batches\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "    train_acc += (y_pred_class == y).sum().item() / len(y_pred)\n",
        "\n",
        "  # Adjust metrics to get average loss and accuracy per batch\n",
        "  train_loss /= len(dataloader)\n",
        "  train_acc /= len(dataloader)\n",
        "  return train_loss, train_acc"
      ],
      "metadata": {
        "id": "HWv1gnz7ZtkD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# test_step function\n",
        "def test_step(model: torch.nn.Module,\n",
        "              dataloader: torch.utils.data.DataLoader,\n",
        "              loss_fn: torch.nn.Module):\n",
        "  # Put model in eval mode\n",
        "  model.eval();\n",
        "\n",
        "  # Set up test loss and accuracy values\n",
        "  test_loss, test_acc = 0, 0\n",
        "\n",
        "  # Turn on inference context manager\n",
        "  with torch.inference_mode():\n",
        "    # Loop through dataLoader batches\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "      # Send to target device\n",
        "      X, y = X.to(device), y.to(device)\n",
        "      # 1. Forward pass\n",
        "      test_pred = model(X)  # in logits, or test_pred_logits\n",
        "      # 2. Calculate and accumulate loss\n",
        "      test_loss += loss_fn(test_pred, y).item()\n",
        "      # Calculate and accumulate accuracy\n",
        "      test_pred_labels = test_pred.argmax(dim=1)\n",
        "      test_acc += ((test_pred_labels == y).sum().item() / len(test_pred_labels))\n",
        "\n",
        "  # Adjust metrics for average loss, acc per batch\n",
        "  test_loss /= len(dataloader)\n",
        "  test_acc /= len(dataloader)\n",
        "  return test_loss, test_acc"
      ],
      "metadata": {
        "id": "3MdkRGE31pto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a train function\n",
        "from tqdm.auto import tqdm\n",
        "\n",
        "# Take in parms required for training and test steps\n",
        "def train(model: torch.nn.Module,\n",
        "          train_dataloader: torch.utils.data.DataLoader,\n",
        "          test_dataloader: torch.utils.data.DataLoader,\n",
        "          optimizer: torch.optim.Optimizer,\n",
        "          loss_fn: torch.nn.Module = nn.CrossEntropyLoss(),\n",
        "          epochs: int = 5):\n",
        "\n",
        "  # 2. Create empty dictionary\n",
        "  results = {\"train_loss\": [],\n",
        "             \"train_acc\": [],\n",
        "             \"test_loss\": [],\n",
        "             \"test_acc\": []}\n",
        "\n",
        "  # 3. Loop through train and test steps for number of epochs\n",
        "  for epoch in tqdm(range(epochs)):\n",
        "    train_loss, train_acc = train_step(model=model,\n",
        "                                       dataloader=train_dataloader,\n",
        "                                       loss_fn=loss_fn,\n",
        "                                       optimizer=optimizer)\n",
        "    test_loss, test_acc = test_step(model=model,\n",
        "                                    dataloader=test_dataloader,\n",
        "                                    loss_fn=loss_fn)\n",
        "\n",
        "    # 4. Print out what's happening\n",
        "    print(f\"Epoch: {epoch+1} | Train loss: {train_loss:.4f} | Train accuracy: {train_acc:.4f} | \"\n",
        "          f\"Test loss: {test_loss:.4f} | Test accuracy: {test_acc:.4f}\")\n",
        "\n",
        "    # 5. Update results dictionary\n",
        "    # Ensure all data moved to CPU as float for storage\n",
        "    results[\"train_loss\"].append(train_loss.item() if isinstance(train_loss, torch.Tensor) else train_loss)\n",
        "    results[\"train_acc\"].append(train_acc.item() if isinstance(train_acc, torch.Tensor) else train_acc)\n",
        "    results[\"test_loss\"].append(test_loss.item() if isinstance(test_loss, torch.Tensor) else test_loss)\n",
        "    results[\"test_acc\"].append(test_acc.item() if isinstance(test_acc, torch.Tensor) else test_acc)\n",
        "\n",
        "  # Return filled results after all epochs\n",
        "  return results"
      ],
      "metadata": {
        "id": "6Ff8x7yN4F3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test the model\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "# SGD got up to .7333 accuracy with 22 epochs and 15 hidden_units\n",
        "# SGD got up to .8400 accuracy with 25 epochs and 20 hidden_units.  --still doesn't help with single-slice or side-view pizza custom images, maybe because test loss\n",
        "NUM_EPOCHS = 15 #25 #22 #20 #10                                     --stops decreasing while train loss keeps decreasing. Probably still need way more train/test data.\n",
        "\n",
        "# Recreate an instance of TinyVGG\n",
        "model_20 = TinyVGG(input_shape=3,    # of RGB color channels\n",
        "                   hidden_units=20,  #15,#10,\n",
        "                   output_shape=len(train_data_20.classes)).to(device)\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "#optimizer = torch.optim.Adam(params=model_20.parameters(), lr=0.001)\n",
        "optimizer = torch.optim.SGD(params=model_20.parameters(), lr=0.001)  # SGD is working better than Adam\n",
        "\n",
        "# Start timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model_20\n",
        "model_20_results = train(model=model_20,\n",
        "                         train_dataloader=train_dataloader,\n",
        "                         test_dataloader=test_dataloader,\n",
        "                         optimizer=optimizer,\n",
        "                         loss_fn=loss_fn,\n",
        "                         epochs=NUM_EPOCHS)\n",
        "\n",
        "# End and print time\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time - start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "NiMAlbAG7uVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check model_20_results keys\n",
        "model_20_results.keys()"
      ],
      "metadata": {
        "id": "UBCxCLaCASR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract each of the keys above and plot them\n",
        "from typing import Dict, List\n",
        "\n",
        "def plot_loss_curves(results: Dict[str, List[float]]):\n",
        "  \"\"\"Plots training curves of a results dictionary.\n",
        "\n",
        "  Args:\n",
        "      results (dict): dictionary containing list of values, e.g.\n",
        "          {\"train_loss\": [...],\n",
        "           \"train_acc\": [...],\n",
        "           \"test_loss\": [...],\n",
        "           \"test_acc\": [...]}\n",
        "  \"\"\"\n",
        "  # Get the loss values of the results dictionary (training and test)\n",
        "  loss = results['train_loss']\n",
        "  test_loss = results['test_loss']\n",
        "\n",
        "  # Get the accuracy values of the results dictionary (training and test)\n",
        "  accuracy = results['train_acc']\n",
        "  test_accuracy = results['test_acc']\n",
        "\n",
        "  # Figure out how many epochs there were\n",
        "  epochs = range(len(results['train_loss']))\n",
        "\n",
        "  # Set up a plot\n",
        "  plt.figure(figsize=(15, 7))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.plot(epochs, loss, label='train_loss')\n",
        "  plt.plot(epochs, test_loss, label='test_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.plot(epochs, accuracy, label='train_accuracy')\n",
        "  plt.plot(epochs, test_accuracy, label='test_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n",
        "\n",
        "plot_loss_curves(model_20_results)"
      ],
      "metadata": {
        "id": "ZIlzM-Q_AdbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Try augmented transform\n",
        "data_20_augmented_transform = transforms.Compose([\n",
        "    transforms.Resize((224,224)),\n",
        "    transforms.TrivialAugmentWide(num_magnitude_bins=31),\n",
        "    transforms.ToTensor()])\n",
        "\n",
        "# It is generally necessary to apply the same transformations to the test data as were applied to the training set\n",
        "\n",
        "# Turn images into datasets\n",
        "train_data_20_augmented = datasets.ImageFolder(train_data_20_path,\n",
        "                                               transform=data_20_augmented_transform,\n",
        "                                               target_transform=None)\n",
        "test_data_20_augmented = datasets.ImageFolder(test_data_20_path,\n",
        "                                              transform=data_20_augmented_transform)\n",
        "\n",
        "train_data_20_augmented, test_data_20_augmented"
      ],
      "metadata": {
        "id": "KvAP7u0LEGlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn augmented train and test datasets into DataLoaders (making them iterable)\n",
        "train_dataloader_aug = DataLoader(dataset=train_data_20_augmented,\n",
        "                                  batch_size=1,\n",
        "                                  num_workers=1,\n",
        "                                  shuffle=True)\n",
        "test_dataloader_aug = DataLoader(dataset=test_data_20_augmented,\n",
        "                                 batch_size=1,\n",
        "                                 num_workers=1,\n",
        "                                 shuffle=False)\n",
        "train_dataloader_aug, test_dataloader_aug"
      ],
      "metadata": {
        "id": "5kz8a-bKH0k2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create another model for augmented data\n",
        "torch.manual_seed(42)\n",
        "model_20_aug = TinyVGG(input_shape=3,\n",
        "                       hidden_units=10,\n",
        "                       output_shape=len(train_data_20_augmented.classes)).to(device)\n",
        "model_20_aug"
      ],
      "metadata": {
        "id": "LQQ7Kx7QIq4e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and test the augmented model\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model_20.parameters(), lr=0.001)\n",
        "\n",
        "# Start timer\n",
        "from timeit import default_timer as timer\n",
        "start_time = timer()\n",
        "\n",
        "# Train model_20\n",
        "model_20_aug_results = train(model=model_20_aug,\n",
        "                         train_dataloader=train_dataloader_aug,\n",
        "                         test_dataloader=test_dataloader_aug,\n",
        "                         optimizer=optimizer,\n",
        "                         loss_fn=loss_fn,\n",
        "                         epochs=NUM_EPOCHS)\n",
        "\n",
        "# End and print time\n",
        "end_time = timer()\n",
        "print(f\"Total training time: {end_time - start_time:.3f} seconds\")"
      ],
      "metadata": {
        "id": "RS3E9ARzJH-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Augmented transform results look worse than horizontal flip\n",
        "plot_loss_curves(model_20_aug_results)"
      ],
      "metadata": {
        "id": "qFOsCkQ-KSoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# See how augmented transformations look\n",
        "plot_transformed_images(image_paths=image_path_list,\n",
        "                        transform=data_20_transform,\n",
        "                        n=3)"
      ],
      "metadata": {
        "id": "DfpQiuLvLBN0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare models\n",
        "import pandas as pd\n",
        "model_20_df = pd.DataFrame(model_20_results)\n",
        "model_20_aug_df = pd.DataFrame(model_20_aug_results)\n",
        "model_20_df"
      ],
      "metadata": {
        "id": "AZwt3D6pLerm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_20_aug_df"
      ],
      "metadata": {
        "id": "wYWLqQEmMI1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up a plot\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Get number of epochs\n",
        "epochs = range(len(model_20_df))\n",
        "\n",
        "# Plot train loss\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(epochs, model_20_df[\"train_loss\"], label=\"model_20\")\n",
        "plt.plot(epochs, model_20_aug_df[\"train_loss\"], label=\"model_20_aug\")\n",
        "plt.title(\"Train Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot test loss\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(epochs, model_20_df[\"test_loss\"], label=\"model_20\")\n",
        "plt.plot(epochs, model_20_aug_df[\"test_loss\"], label=\"model_20_aug\")\n",
        "plt.title(\"Test Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot train accuracy\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(epochs, model_20_df[\"train_acc\"], label=\"model_20\")\n",
        "plt.plot(epochs, model_20_aug_df[\"train_acc\"], label=\"model_20_aug\")\n",
        "plt.title(\"Train Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()\n",
        "\n",
        "# Plot test accuracy\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(epochs, model_20_df[\"test_acc\"], label=\"model_20\")\n",
        "plt.plot(epochs, model_20_aug_df[\"test_acc\"], label=\"model_20_aug\")\n",
        "plt.title(\"Test Accuracy\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "JXTejm2gryKG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 8. Make a prediction on your own custom image\n",
        "# Download custom image\n",
        "import requests\n",
        "\n",
        "# Get multiple custom images\n",
        "\"\"\" to get raw address:  right click jpeg file name in main repository view, select copy link address, paste into browser and enter\n",
        "    then right click on image, select copy link address = https://github.com/lanehale/pytorch-deep-learning/blob/main/cheese-pizza.jpeg?raw=true\n",
        "    paste into browser and enter to get url format below\n",
        "\"\"\"\n",
        "urls = [\n",
        "    \"https://raw.githubusercontent.com/lanehale/pytorch-deep-learning/refs/heads/main/cheese-pizza.jpeg\",\n",
        "    \"https://raw.githubusercontent.com/lanehale/pytorch-deep-learning/refs/heads/main/pizza-slice.jpeg\",\n",
        "    \"https://raw.githubusercontent.com/lanehale/pytorch-deep-learning/refs/heads/main/pizza-slice2.jpeg\",\n",
        "    \"https://raw.githubusercontent.com/lanehale/pytorch-deep-learning/refs/heads/main/pizza-sliced.jpeg\",\n",
        "    \"https://raw.githubusercontent.com/lanehale/pytorch-deep-learning/refs/heads/main/pizza-sliced2.jpeg\",\n",
        "    \"https://raw.githubusercontent.com/lanehale/pytorch-deep-learning/refs/heads/main/pizza-partial-view.jpeg\",\n",
        "    \"https://raw.githubusercontent.com/lanehale/pytorch-deep-learning/refs/heads/main/pizza-partial-view2.jpeg\",\n",
        "    \"https://raw.githubusercontent.com/lanehale/pytorch-deep-learning/refs/heads/main/pizza-side-view.jpeg\"\n",
        "]\n",
        "\n",
        "filenames = [\n",
        "    \"cheese-pizza.jpeg\",\n",
        "    \"pizza-slice.jpeg\",\n",
        "    \"pizza-slice2.jpeg\",\n",
        "    \"pizza-sliced.jpeg\",\n",
        "    \"pizza-sliced2.jpeg\",\n",
        "    \"pizza-partial-view.jpeg\",\n",
        "    \"pizza-partial-view2.jpeg\",\n",
        "    \"pizza-side-view.jpeg\"\n",
        "]\n",
        "\n",
        "if len(urls) != len(filenames):\n",
        "  raise ValueError(\"The number of URLs and filenames must be the same.\")\n",
        "\n",
        "# Download the images if they don't already exist\n",
        "if (data_path / \"cheese-pizza.jpeg\").is_file():\n",
        "  print(f\"Custom images already exist, skipping download.\")\n",
        "else:\n",
        "  for i, url in enumerate(urls):\n",
        "    try:\n",
        "      response = requests.get(url)\n",
        "      response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "      custom_image_path = data_path / filenames[i]\n",
        "\n",
        "      with open(custom_image_path, \"wb\") as f:\n",
        "        f.write(response.content)\n",
        "\n",
        "      print(f\"DownLoading {custom_image_path}...\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "      print(f\"Error downloading {url}: {e}\")\n",
        "    except Exception as e:\n",
        "      print(f\"An unexpected error occurred: {e}\")"
      ],
      "metadata": {
        "id": "uHUjvTI-ypvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!rm data/*jpeg\n",
        "!ls data/"
      ],
      "metadata": {
        "id": "YIQBAirdDYk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "\n",
        "# Choose a custom image\n",
        "custom_image_path = data_path / \"pizza-slice.jpeg\"\n",
        "\n",
        "# Read in custom image\n",
        "custom_image_uint8 = torchvision.io.read_image(str(custom_image_path))\n",
        "\n",
        "custom_image_uint8, custom_image_uint8.dtype, custom_image_uint8.shape"
      ],
      "metadata": {
        "id": "vo1CorGDEH8y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load in custom image and convert the tensor values to float32\n",
        "custom_image = torchvision.io.read_image(str(custom_image_path)).type(torch.float32)\n",
        "\n",
        "# Divide the image pixel values by 255 to get them between [0, 1]\n",
        "custom_image /= 255\n",
        "\n",
        "custom_image, custom_image.dtype, custom_image.shape"
      ],
      "metadata": {
        "id": "mU8cMQ2mOkuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the custom image\n",
        "plt.imshow(custom_image.permute(1, 2, 0))  # need to permute image dimensions from CHW -> HWC otherwise matplotlib will error\n",
        "plt.title(f\"Custom image shape: {custom_image.shape}\")\n",
        "plt.axis(False);"
      ],
      "metadata": {
        "id": "NjCGOKDkPZcW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create transform pipeline to resize image\n",
        "custom_image_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224))])\n",
        "\n",
        "# Transform custom image\n",
        "custom_image_transformed = custom_image_transform(custom_image)\n",
        "\n",
        "custom_image_transformed.shape"
      ],
      "metadata": {
        "id": "xKCB7e9SP6R9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add an extra dimension to image\n",
        "custom_image_transformed_with_batch_dim = custom_image_transformed.unsqueeze(dim=0)\n",
        "\n",
        "custom_image_transformed.shape, custom_image_transformed_with_batch_dim.shape"
      ],
      "metadata": {
        "id": "vnj4pzoQnruj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_20.eval()\n",
        "with torch.inference_mode():\n",
        "  # Make a prediction on image with an extra dimension\n",
        "  custom_image_pred = model_20(custom_image_transformed.unsqueeze(dim=0).to(device))\n",
        "  custom_image_pred_with_batch = model_20(custom_image_transformed_with_batch_dim.to(device))\n",
        "\n",
        "custom_image_pred, custom_image_pred_with_batch"
      ],
      "metadata": {
        "id": "qWhGoxHEoYO0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print out prediction logits\n",
        "print(f\"Prediction logits: {custom_image_pred}\")\n",
        "\n",
        "# Convert logits to prediction probabilities\n",
        "custom_image_pred_probs = torch.softmax(custom_image_pred, dim=1)  # using softmax for multi-class classification\n",
        "print(f\"Prediction probabilities: {custom_image_pred_probs}\")\n",
        "\n",
        "# Convert probabilities to labels\n",
        "custom_image_pred_label = torch.argmax(custom_image_pred_probs, dim=1)\n",
        "print(f\"Prediction label: {custom_image_pred_label}\")"
      ],
      "metadata": {
        "id": "3aZhkYTeoPT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Find the predicted label\n",
        "custom_image_pred_class = class_names[custom_image_pred_label.cpu().item()]  # pred label has to be on cpu\n",
        "custom_image_pred_class"
      ],
      "metadata": {
        "id": "F5UWLL54qRXr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicted label using custom pizza slice image above is wrong, got sushi\n",
        "# custom_image_pred_with_batch has same logits so it's no different\n",
        "custom_image_pred2_probs = torch.softmax(custom_image_pred_with_batch, dim=1)\n",
        "custom_image_pred2_label = torch.argmax(custom_image_pred2_probs, dim=1)\n",
        "custom_image_pred2_class = class_names[custom_image_pred2_label.cpu().item()]\n",
        "custom_image_pred2_class, custom_image_pred2_label, custom_image_pred2_probs"
      ],
      "metadata": {
        "id": "D3UnCTxyq-Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A function that makes a prediction on a target image and plots the image with its prediction\n",
        "def pred_and_plot_image(model: torch.nn.Module,\n",
        "                        image_path: str,\n",
        "                        class_names: List[str] = None,\n",
        "                        transform = None,\n",
        "                        device: torch.device = device):\n",
        "  # 1. Load in an image and convert tensor values to float32\n",
        "  target_image = torchvision.io.read_image(str(image_path)).type(torch.float32)\n",
        "\n",
        "  # 2. Divide the image pixel values by 255 to get them between 0 and 1\n",
        "  target_image /= 255\n",
        "\n",
        "  # 3. Transform if necessary\n",
        "  if transform:\n",
        "    target_image = transform(target_image)\n",
        "\n",
        "  # 4. Make sure model is on target device\n",
        "  model.to(device)\n",
        "\n",
        "  # 5. Turn on model evaluation and inference modes\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    # Add an extra dimension to image\n",
        "    target_image = target_image.unsqueeze(dim=0)\n",
        "    # Make a prediction on image with an extra dimension and send it to the target device\n",
        "    target_image_pred = model(target_image.to(device))\n",
        "\n",
        "  # 6. Convert logits to probabilities\n",
        "  target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
        "\n",
        "  # 7. Convert probs to label\n",
        "  target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
        "\n",
        "  # 8. Plot the image alongside the prediction and prediction probability\n",
        "  plt.imshow(target_image.squeeze().permute(1, 2, 0))  # make sure it's right size for matplotlib\n",
        "  if class_names:\n",
        "    title = f\"Pred: {class_names[target_image_pred_label.cpu()]} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "  else:\n",
        "    title = f\"Pred: {target_image_pred_label} | Prob: {target_image_pred_probs.max().cpu():.3f}\"\n",
        "  plt.title(title)\n",
        "  plt.axis(False);"
      ],
      "metadata": {
        "id": "PdA9SjJLtH3p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediction on our custom image\n",
        "custom_image_path = data_path / \"pizza-slice.jpeg\"\n",
        "\n",
        "pred_and_plot_image(model=model_20,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names,\n",
        "                    transform=custom_image_transform,\n",
        "                    device=device)"
      ],
      "metadata": {
        "id": "rbWW-ykXwDtT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose another custom image\n",
        "custom_image_path = data_path / \"pizza-sliced.jpeg\"\n",
        "\n",
        "pred_and_plot_image(model=model_20,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names,\n",
        "                    transform=custom_image_transform,\n",
        "                    device=device)"
      ],
      "metadata": {
        "id": "vHIgjnUi1pYr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose another custom image\n",
        "custom_image_path = data_path / \"pizza-sliced2.jpeg\"\n",
        "\n",
        "pred_and_plot_image(model=model_20,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names,\n",
        "                    transform=custom_image_transform,\n",
        "                    device=device)"
      ],
      "metadata": {
        "id": "2-e2h96O13xF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose another custom image\n",
        "custom_image_path = data_path / \"cheese-pizza.jpeg\"\n",
        "\n",
        "pred_and_plot_image(model=model_20,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names,\n",
        "                    transform=custom_image_transform,\n",
        "                    device=device)"
      ],
      "metadata": {
        "id": "6xOKILYp1_YK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose another custom image\n",
        "custom_image_path = data_path / \"pizza-slice2.jpeg\"\n",
        "\n",
        "pred_and_plot_image(model=model_20,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names,\n",
        "                    transform=custom_image_transform,\n",
        "                    device=device)"
      ],
      "metadata": {
        "id": "eZagQ6re2IJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose another custom image\n",
        "custom_image_path = data_path / \"pizza-partial-view.jpeg\"\n",
        "\n",
        "pred_and_plot_image(model=model_20,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names,\n",
        "                    transform=custom_image_transform,\n",
        "                    device=device)"
      ],
      "metadata": {
        "id": "dDUP31Wc2Ub5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose another custom image\n",
        "custom_image_path = data_path / \"pizza-partial-view2.jpeg\"\n",
        "\n",
        "pred_and_plot_image(model=model_20,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names,\n",
        "                    transform=custom_image_transform,\n",
        "                    device=device)"
      ],
      "metadata": {
        "id": "B5hWg2em2cx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose another custom image\n",
        "custom_image_path = data_path / \"pizza-side-view.jpeg\"\n",
        "\n",
        "pred_and_plot_image(model=model_20,\n",
        "                    image_path=custom_image_path,\n",
        "                    class_names=class_names,\n",
        "                    transform=custom_image_transform,\n",
        "                    device=device)"
      ],
      "metadata": {
        "id": "7XUQ5miT2mxA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "2BhthntUCYOO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}