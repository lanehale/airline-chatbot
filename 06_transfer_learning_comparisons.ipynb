{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOtrbTV9N5JJs/zAPtgHeua",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lanehale/airline-chatbot/blob/main/06_transfer_learning_comparisons.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GitHub doesn't handle all output types. The most informative outputs have been included throughout, with links to images when necessary.\n",
        "\n",
        "Optionally, see the full output in Colab notebook - https://colab.research.google.com/drive/15XgZ1UCIrpu7VwIzm6U4UrCUKGt4qRWf?usp=sharing"
      ],
      "metadata": {
        "id": "fFCwBW5HZggH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Moved pip installs outside of py scripts as apparently it's best practice.\n",
        "\"\"\"\n",
        "# See if torchmetrics exists, if not, install it\n",
        "try:\n",
        "  import torchmetrics, mlxtend\n",
        "  print(\"torchmetrics already installed.\")\n",
        "except:\n",
        "  print(\"Installing torchmetrics...\")\n",
        "  !pip install -q torchmetrics -U mlxtend\n",
        "  import torchmetrics, mlxtend\n",
        "  print(\"Done installing torchmetrics.\")"
      ],
      "metadata": {
        "id": "gBResdvgY8hT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B7N0GcWPTARQ"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Run several transfer learning model experiments with different hyperparameters.\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "Create the going_modular folder and move in its scripts.\n",
        "\"\"\"\n",
        "import os\n",
        "\n",
        "# Try to import the going_modular directory, download it from GitHub if it doesn't work\n",
        "try:\n",
        "  from going_modular import data_setup, engine, get_any_data\n",
        "  print(\"going_modular scripts already downloaded.\")\n",
        "except:\n",
        "  \"\"\"\n",
        "  This block attempts to download a GitHub repository,\n",
        "  move a specific directory from the downloaded repository to the current working directory,\n",
        "  and then remove the downloaded repository.\n",
        "  \"\"\"\n",
        "  # Get the going_modular scripts\n",
        "  print(\"[INFO] Couldn't find going_modular scripts... downloading them from GitHub.\")\n",
        "\n",
        "  # Clone the git repository\n",
        "  !git clone https://github.com/lanehale/pytorch-deep-learning\n",
        "\n",
        "  # When cloning a GitHub repository, the directory structure on your local machine doesn't include /tree/main/, so it shouldn't be included in the mv command.\n",
        "  # The . at the end of the command tells mv to move the specified directory into the current working directory.\n",
        "  !mv pytorch-deep-learning/going_modular .\n",
        "\n",
        "  # remove the downloaded repository\n",
        "  !rm -rf pytorch-deep-learning\n",
        "\n",
        "  # move these two files out to parent directory\n",
        "  !mv going_modular/train.py .\n",
        "  !mv going_modular/predict.py .\n",
        "\n",
        "  from going_modular import data_setup, engine, get_any_data\n",
        "\n",
        "print(\">!ls\")\n",
        "!ls\n",
        "print(\">!ls going_modular\")\n",
        "!ls going_modular"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 10% dataset\n",
        "get_any_data.from_path(from_path=\"pizza_steak_sushi.zip\", image_dir=\"pizza_steak_sushi\")"
      ],
      "metadata": {
        "id": "ZHL1yjciUIyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "from pathlib import Path\n",
        "from going_modular import pretrained_confmat as pretrained\n",
        "\n",
        "# Setup device agnostic code\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "device\n",
        "\n",
        "image_path = Path(\"data/pizza_steak_sushi\")\n",
        "\n",
        "# Set up dirs\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"    # train/test ratio is actually 67/33 (150/225, 75/225)\n",
        "\n",
        "test_image_path_list = list(Path(test_dir).glob(\"*/*.jpg\"))  # this is only used for predictions\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "dropout = 0.2\n",
        "in_features = 1280\n",
        "optimizer_type = \"Adam\"\n",
        "optimizer_lr = 0.001\n",
        "\n",
        "weights_b0 = torchvision.models.EfficientNet_B0_Weights.DEFAULT  # .DEFAULT = best available weights from pretraining on ImageNet\n",
        "weights_b2 = torchvision.models.EfficientNet_B2_Weights.DEFAULT\n",
        "\n",
        "\"\"\"\n",
        "Train 10% dataset for 5 epochs using Eff_B0\n",
        "\"\"\"\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Set up the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
        "model_b0_5x_10p = torchvision.models.efficientnet_b0(weights=weights_b0).to(device)\n",
        "\n",
        "results_b0_5x_10p, pred_list_b0_5x_10p = pretrained.run_model(\n",
        "    model=model_b0_5x_10p,\n",
        "    weights=weights_b0,\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    dropout=dropout,\n",
        "    in_features=in_features,\n",
        "    optimizer_type=optimizer_type,\n",
        "    optimizer_lr=optimizer_lr,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    image_data=test_image_path_list,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "LZaEpYaAjGUl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Downloading: \"https://download.pytorch.org/models/efficientnet_b0_rwightman-7f5810bc.pth\" to /root/.cache/torch/hub/checkpoints/efficientnet_b0_rwightman-7f5810bc.pth\n",
        "100%|██████████| 20.5M/20.5M [00:00<00:00, 155MB/s]\n",
        "Training the model...\n",
        "100%\n",
        " 5/5 [00:12<00:00,  2.52s/it]\n",
        "Epoch: 1 | train_loss: 1.0313 | train_acc: 0.5117 | test_loss: 0.8690 | test_acc: 0.6723\n",
        "Epoch: 2 | train_loss: 0.8755 | train_acc: 0.6953 | test_loss: 0.7995 | test_acc: 0.7027\n",
        "Epoch: 3 | train_loss: 0.7953 | train_acc: 0.6523 | test_loss: 0.6977 | test_acc: 0.8248\n",
        "Epoch: 4 | train_loss: 0.7233 | train_acc: 0.7656 | test_loss: 0.5791 | test_acc: 0.9062\n",
        "Epoch: 5 | train_loss: 0.6085 | train_acc: 0.8906 | test_loss: 0.5739 | test_acc: 0.8759\n",
        "[INFO] Total running time: 12.952 seconds\n",
        "Predicting with image_data...\n",
        "Max test acc: 0.906 | Min test loss: 0.574\n",
        "```\n",
        "Image Link - Confusion Matrix for EffNetB0 5 epochs 10% data - https://github.com/lanehale/pytorch-deep-learning/blob/main/06-output-images/Confusion%20Matrix%20model_b0_5x_10p.png"
      ],
      "metadata": {
        "id": "533ig-hKluyw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Train 10% dataset for 10 epochs using Eff_B0\n",
        "\"\"\"\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Set up the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
        "model_b0_10x_10p = torchvision.models.efficientnet_b0(weights=weights_b0).to(device)\n",
        "\n",
        "results_b0_10x_10p, pred_list_b0_10x_10p = pretrained.run_model(\n",
        "    model=model_b0_10x_10p,\n",
        "    weights=weights_b0,\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    dropout=dropout,\n",
        "    in_features=in_features,\n",
        "    optimizer_type=optimizer_type,\n",
        "    optimizer_lr=optimizer_lr,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    image_data=test_image_path_list,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "aGBf1ewYo5rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Training the model...\n",
        "100%\n",
        " 10/10 [00:23<00:00,  2.30s/it]\n",
        "Epoch: 1 | train_loss: 1.0313 | train_acc: 0.5117 | test_loss: 0.8690 | test_acc: 0.6723\n",
        "Epoch: 2 | train_loss: 0.8755 | train_acc: 0.6953 | test_loss: 0.7995 | test_acc: 0.7027\n",
        "Epoch: 3 | train_loss: 0.7953 | train_acc: 0.6523 | test_loss: 0.6977 | test_acc: 0.8248\n",
        "Epoch: 4 | train_loss: 0.7233 | train_acc: 0.7656 | test_loss: 0.5791 | test_acc: 0.9062\n",
        "Epoch: 5 | train_loss: 0.6085 | train_acc: 0.8906 | test_loss: 0.5739 | test_acc: 0.8759\n",
        "Epoch: 6 | train_loss: 0.5446 | train_acc: 0.9375 | test_loss: 0.5947 | test_acc: 0.8456\n",
        "Epoch: 7 | train_loss: 0.5724 | train_acc: 0.7891 | test_loss: 0.5502 | test_acc: 0.8352\n",
        "Epoch: 8 | train_loss: 0.4594 | train_acc: 0.9531 | test_loss: 0.4931 | test_acc: 0.8561\n",
        "Epoch: 9 | train_loss: 0.5643 | train_acc: 0.7891 | test_loss: 0.4967 | test_acc: 0.8456\n",
        "Epoch: 10 | train_loss: 0.4993 | train_acc: 0.7969 | test_loss: 0.4784 | test_acc: 0.8561\n",
        "[INFO] Total running time: 23.898 seconds\n",
        "Predicting with image_data...\n",
        "Max test acc: 0.906 | Min test loss: 0.478\n",
        "```\n",
        "Image Link - Confusion Matrix for EffNetB0 10 epochs 10% data - https://github.com/lanehale/pytorch-deep-learning/blob/main/06-output-images/Confusion%20Matrix%20model_b0_10x_10p.png\n",
        "\n"
      ],
      "metadata": {
        "id": "ZlGbSzUKmKO-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Train 10% dataset for 5 epochs using Eff_B2\n",
        "\"\"\"\n",
        "dropout = 0.3\n",
        "in_features = 1408\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Set up the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
        "model_b2_5x_10p = torchvision.models.efficientnet_b2(weights=weights_b2).to(device)\n",
        "\n",
        "results_b2_5x_10p, pred_list_b2_5x_10p = pretrained.run_model(\n",
        "    model=model_b2_5x_10p,\n",
        "    weights=weights_b2,\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    dropout=dropout,\n",
        "    in_features=in_features,\n",
        "    optimizer_type=optimizer_type,\n",
        "    optimizer_lr=optimizer_lr,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    image_data=test_image_path_list,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "9bZgFDq_o2Cx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Train 10% dataset for 10 epochs using Eff_B2\n",
        "\"\"\"\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Set up the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
        "model_b2_10x_10p = torchvision.models.efficientnet_b2(weights=weights_b2).to(device)\n",
        "\n",
        "results_b2_10x_10p, pred_list_b2_10x_10p = pretrained.run_model(\n",
        "    model=model_b2_10x_10p,\n",
        "    weights=weights_b2,\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    dropout=dropout,\n",
        "    in_features=in_features,\n",
        "    optimizer_type=optimizer_type,\n",
        "    optimizer_lr=optimizer_lr,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    image_data=test_image_path_list,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "W6W7d1k-ou8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Training the model...\n",
        "100%\n",
        " 10/10 [00:34<00:00,  3.62s/it]\n",
        "Epoch: 1 | train_loss: 1.0852 | train_acc: 0.3867 | test_loss: 0.9224 | test_acc: 0.7538\n",
        "Epoch: 2 | train_loss: 0.9143 | train_acc: 0.6641 | test_loss: 0.8252 | test_acc: 0.8059\n",
        "Epoch: 3 | train_loss: 0.8217 | train_acc: 0.7539 | test_loss: 0.6787 | test_acc: 0.8968\n",
        "Epoch: 4 | train_loss: 0.6747 | train_acc: 0.9023 | test_loss: 0.6456 | test_acc: 0.8665\n",
        "Epoch: 5 | train_loss: 0.6669 | train_acc: 0.8242 | test_loss: 0.6390 | test_acc: 0.8466\n",
        "Epoch: 6 | train_loss: 0.5795 | train_acc: 0.8008 | test_loss: 0.5625 | test_acc: 0.9072\n",
        "Epoch: 7 | train_loss: 0.5668 | train_acc: 0.8125 | test_loss: 0.5567 | test_acc: 0.9280\n",
        "Epoch: 8 | train_loss: 0.5009 | train_acc: 0.9414 | test_loss: 0.5881 | test_acc: 0.8674\n",
        "Epoch: 9 | train_loss: 0.5177 | train_acc: 0.8047 | test_loss: 0.5837 | test_acc: 0.8570\n",
        "Epoch: 10 | train_loss: 0.4651 | train_acc: 0.9453 | test_loss: 0.5410 | test_acc: 0.8570\n",
        "[INFO] Total running time: 34.646 seconds\n",
        "Predicting with image_data...\n",
        "Max test acc: 0.928 | Min test loss: 0.541\n",
        "```\n",
        "Image Link - Confusion Matrix for EffNetB2 10 epochs 10% data - https://github.com/lanehale/pytorch-deep-learning/blob/main/06-output-images/Confusion%20Matrix%20model_b2_10x_10p.png\n"
      ],
      "metadata": {
        "id": "9N0QBorgmjct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get 20% dataset\n",
        "from going_modular import get_any_data\n",
        "\n",
        "get_any_data.from_path(from_path=\"pizza_steak_sushi_20_percent.zip\", image_dir=\"pizza_steak_sushi_20\")"
      ],
      "metadata": {
        "id": "M_JBp6qJn_uq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_path = Path(\"data/pizza_steak_sushi_20\")\n",
        "\n",
        "# Set up dirs\n",
        "train_dir = image_path / \"train\"\n",
        "test_dir = image_path / \"test\"    # use 20% test path to maintain 67/33 train/test ratio (300/450, 150/450)\n",
        "\n",
        "test_image_path_list_20 = list(Path(test_dir).glob(\"*/*.jpg\"))  # this is only used for predictions\n",
        "\n",
        "\"\"\"\n",
        "Train 20% dataset for 5 epochs using Eff_B0\n",
        "\"\"\"\n",
        "dropout = 0.2\n",
        "in_features = 1280\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Set up the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
        "model_b0_5x_20p = torchvision.models.efficientnet_b0(weights=weights_b0).to(device)\n",
        "\n",
        "results_b0_5x_20p, pred_list_b0_5x_20p = pretrained.run_model(\n",
        "    model=model_b0_5x_20p,\n",
        "    weights=weights_b0,\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    dropout=dropout,\n",
        "    in_features=in_features,\n",
        "    optimizer_type=optimizer_type,\n",
        "    optimizer_lr=optimizer_lr,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    image_data=test_image_path_list_20,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "uM1g11qNpy-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Train 20% dataset for 10 epochs using Eff_B0\n",
        "\"\"\"\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Set up the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
        "model_b0_10x_20p = torchvision.models.efficientnet_b0(weights=weights_b0).to(device)\n",
        "\n",
        "results_b0_10x_20p, pred_list_b0_10x_20p = pretrained.run_model(\n",
        "    model=model_b0_10x_20p,\n",
        "    weights=weights_b0,\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    dropout=dropout,\n",
        "    in_features=in_features,\n",
        "    optimizer_type=optimizer_type,\n",
        "    optimizer_lr=optimizer_lr,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    image_data=test_image_path_list_20,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "py2wdnVvqmF3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Training the model...\n",
        "100%\n",
        " 10/10 [00:47<00:00,  4.67s/it]\n",
        "Epoch: 1 | train_loss: 0.9514 | train_acc: 0.5979 | test_loss: 0.6660 | test_acc: 0.8568\n",
        "Epoch: 2 | train_loss: 0.6948 | train_acc: 0.7896 | test_loss: 0.5529 | test_acc: 0.8670\n",
        "Epoch: 3 | train_loss: 0.5757 | train_acc: 0.8354 | test_loss: 0.4710 | test_acc: 0.8818\n",
        "Epoch: 4 | train_loss: 0.5072 | train_acc: 0.8417 | test_loss: 0.4227 | test_acc: 0.8881\n",
        "Epoch: 5 | train_loss: 0.4902 | train_acc: 0.8063 | test_loss: 0.3990 | test_acc: 0.8881\n",
        "Epoch: 6 | train_loss: 0.3797 | train_acc: 0.9187 | test_loss: 0.3863 | test_acc: 0.9006\n",
        "Epoch: 7 | train_loss: 0.3710 | train_acc: 0.9104 | test_loss: 0.3517 | test_acc: 0.9097\n",
        "Epoch: 8 | train_loss: 0.3500 | train_acc: 0.8917 | test_loss: 0.3306 | test_acc: 0.9102\n",
        "Epoch: 9 | train_loss: 0.2974 | train_acc: 0.9187 | test_loss: 0.3117 | test_acc: 0.9006\n",
        "Epoch: 10 | train_loss: 0.3665 | train_acc: 0.8771 | test_loss: 0.3169 | test_acc: 0.8943\n",
        "[INFO] Total running time: 47.406 seconds\n",
        "Predicting with image_data...\n",
        "Max test acc: 0.910 | Min test loss: 0.312\n",
        "```\n",
        "Image Link - Confusion Matrix for EffNetB0 10 epochs 20% data - https://github.com/lanehale/pytorch-deep-learning/blob/main/06-output-images/Consfusion%20Matrix%20model_b0_10x_20p.png\n"
      ],
      "metadata": {
        "id": "IuvSOOKom_jl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Train 20% dataset for 5 epochs using Eff_B2\n",
        "\"\"\"\n",
        "dropout = 0.3\n",
        "in_features = 1408\n",
        "NUM_EPOCHS = 5\n",
        "\n",
        "# Set up the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
        "model_b2_5x_20p = torchvision.models.efficientnet_b2(weights=weights_b2).to(device)\n",
        "\n",
        "results_b2_5x_20p, pred_list_b2_5x_20p = pretrained.run_model(\n",
        "    model=model_b2_5x_20p,\n",
        "    weights=weights_b2,\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    dropout=dropout,\n",
        "    in_features=in_features,\n",
        "    optimizer_type=optimizer_type,\n",
        "    optimizer_lr=optimizer_lr,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    image_data=test_image_path_list_20,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "QvUn-Ra-q-gI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Train 20% dataset for 10 epochs using Eff_B2\n",
        "\"\"\"\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "# Set up the model with pretrained weights and send it to the target device (torchvision v0.13+)\n",
        "model_b2_10x_20p = torchvision.models.efficientnet_b2(weights=weights_b2).to(device)\n",
        "\n",
        "results_b2_10x_20p, pred_list_b2_10x_20p = pretrained.run_model(\n",
        "    model=model_b2_10x_20p,\n",
        "    weights=weights_b2,\n",
        "    train_dir=train_dir,\n",
        "    test_dir=test_dir,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    dropout=dropout,\n",
        "    in_features=in_features,\n",
        "    optimizer_type=optimizer_type,\n",
        "    optimizer_lr=optimizer_lr,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    image_data=test_image_path_list_20,\n",
        "    device=device\n",
        ")"
      ],
      "metadata": {
        "id": "5Lef6LGQq8yA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "Training the model...\n",
        "100%\n",
        " 10/10 [00:59<00:00,  5.89s/it]\n",
        "Epoch: 1 | train_loss: 0.9791 | train_acc: 0.5604 | test_loss: 0.7128 | test_acc: 0.9011\n",
        "Epoch: 2 | train_loss: 0.7206 | train_acc: 0.8063 | test_loss: 0.5769 | test_acc: 0.9443\n",
        "Epoch: 3 | train_loss: 0.5971 | train_acc: 0.7937 | test_loss: 0.4906 | test_acc: 0.9437\n",
        "Epoch: 4 | train_loss: 0.5227 | train_acc: 0.8271 | test_loss: 0.4484 | test_acc: 0.9222\n",
        "Epoch: 5 | train_loss: 0.4196 | train_acc: 0.8917 | test_loss: 0.3825 | test_acc: 0.9375\n",
        "Epoch: 6 | train_loss: 0.3838 | train_acc: 0.9083 | test_loss: 0.3493 | test_acc: 0.9443\n",
        "Epoch: 7 | train_loss: 0.3517 | train_acc: 0.9208 | test_loss: 0.3165 | test_acc: 0.9688\n",
        "Epoch: 8 | train_loss: 0.3706 | train_acc: 0.9062 | test_loss: 0.3061 | test_acc: 0.9534\n",
        "Epoch: 9 | train_loss: 0.3070 | train_acc: 0.9396 | test_loss: 0.2988 | test_acc: 0.9597\n",
        "Epoch: 10 | train_loss: 0.3613 | train_acc: 0.8958 | test_loss: 0.2692 | test_acc: 0.9750\n",
        "[INFO] Total running time: 59.450 seconds\n",
        "Predicting with image_data...\n",
        "Max test acc: 0.975 | Min test loss: 0.269\n",
        "```\n",
        "Image Link - Confusion Matrix for EffNetB2 10 epochs 20% data - https://github.com/lanehale/pytorch-deep-learning/blob/main/06-output-images/Confusion%20Matrix%20model_b2_10x_20p.png"
      ],
      "metadata": {
        "id": "Fmd5MGD2crf4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a function to display results\n",
        "def compare_results(pred_list, name):\n",
        "  false_count = 0\n",
        "  for pred in pred_list:\n",
        "    if pred['correct'] == False:\n",
        "      false_count += 1\n",
        "  false_percent = 100 * false_count / len(pred_list)\n",
        "  print(\n",
        "      f\"{name :<10} | False predictions: {false_count :<2} out of {len(pred_list) :<3}, \"\n",
        "      f\"or {false_percent:5.2f}% wrong, \"\n",
        "      f\"{(100.0 - false_percent):.2f}% right\"\n",
        "  )"
      ],
      "metadata": {
        "id": "hICM2Gu7ruxb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "compare_results(pred_list_b0_5x_10p, \"b0_5x_10p\")\n",
        "compare_results(pred_list_b2_5x_10p, \"b2_5x_10p\")\n",
        "compare_results(pred_list_b0_10x_10p, \"b0_10x_10p\")\n",
        "compare_results(pred_list_b2_10x_10p, \"b2_10x_10p\")\n",
        "compare_results(pred_list_b0_5x_20p, \"b0_5x_20p\")\n",
        "compare_results(pred_list_b2_5x_20p, \"b2_5x_20p\")\n",
        "compare_results(pred_list_b0_10x_20p, \"b0_10x_20p\")\n",
        "compare_results(pred_list_b2_10x_20p, \"b2_10x_20p\")"
      ],
      "metadata": {
        "id": "lnxesQ61tPMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "b0_5x_10p  | False predictions: 10 out of 75 , or 13.33% wrong, 86.67% right\n",
        "b2_5x_10p  | False predictions: 9  out of 75 , or 12.00% wrong, 88.00% right\n",
        "b0_10x_10p | False predictions: 10 out of 75 , or 13.33% wrong, 86.67% right\n",
        "b2_10x_10p | False predictions: 8  out of 75 , or 10.67% wrong, 89.33% right\n",
        "b0_5x_20p  | False predictions: 17 out of 150, or 11.33% wrong, 88.67% right\n",
        "b2_5x_20p  | False predictions: 10 out of 150, or  6.67% wrong, 93.33% right\n",
        "b0_10x_20p | False predictions: 16 out of 150, or 10.67% wrong, 89.33% right\n",
        "b2_10x_20p | False predictions: 4  out of 150, or  2.67% wrong, 97.33% right\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "S8xcrtEd_pz4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Max test acc: {max(results_b0_5x_10p['test_acc']):.3f} | Min test loss: {min(results_b0_5x_10p['test_loss']):.3f}\")\n",
        "print(f\"Max test acc: {max(results_b2_5x_10p['test_acc']):.3f} | Min test loss: {min(results_b2_5x_10p['test_loss']):.3f}\")\n",
        "print(f\"Max test acc: {max(results_b0_5x_20p['test_acc']):.3f} | Min test loss: {min(results_b0_5x_20p['test_loss']):.3f}\")\n",
        "print(f\"Max test acc: {max(results_b2_5x_20p['test_acc']):.3f} | Min test loss: {min(results_b2_5x_20p['test_loss']):.3f}\")\n",
        "print()\n",
        "print(f\"Max test acc: {max(results_b0_10x_10p['test_acc']):.3f} | Min test loss: {min(results_b0_10x_10p['test_loss']):.3f}\")\n",
        "print(f\"Max test acc: {max(results_b2_10x_10p['test_acc']):.3f} | Min test loss: {min(results_b2_10x_10p['test_loss']):.3f}\")\n",
        "print(f\"Max test acc: {max(results_b0_10x_20p['test_acc']):.3f} | Min test loss: {min(results_b0_10x_20p['test_loss']):.3f}\")\n",
        "print(f\"Max test acc: {max(results_b2_10x_20p['test_acc']):.3f} | Min test loss: {min(results_b2_10x_20p['test_loss']):.3f}\")"
      ],
      "metadata": {
        "id": "UE8Qa2Sb5UN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "Max test acc: 0.906 | Min test loss: 0.574\n",
        "Max test acc: 0.897 | Min test loss: 0.639\n",
        "Max test acc: 0.888 | Min test loss: 0.399\n",
        "Max test acc: 0.944 | Min test loss: 0.382\n",
        "\n",
        "Max test acc: 0.906 | Min test loss: 0.478\n",
        "Max test acc: 0.928 | Min test loss: 0.541\n",
        "Max test acc: 0.910 | Min test loss: 0.312\n",
        "Max test acc: 0.975 | Min test loss: 0.269\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "d4_XmILZ_7KX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained.plot_N_most_wrong(pred_list_b0_5x_10p, n=3)"
      ],
      "metadata": {
        "id": "J7cvnsLD8wll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Links - top 3 worst predictions for EffNetB0 5 epochs 10% data:\n",
        "\n",
        "https://github.com/lanehale/pytorch-deep-learning/blob/main/06-output-images/b0_5x_10p_worst_prediction.png\n",
        "\n",
        "https://github.com/lanehale/pytorch-deep-learning/blob/main/06-output-images/b0_5x_10p_worst_prediction_2.png\n",
        "\n",
        "https://github.com/lanehale/pytorch-deep-learning/blob/main/06-output-images/b0_5x_10p_worst_prediction_3.png"
      ],
      "metadata": {
        "id": "AZ32B9tCvdFv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained.plot_N_most_wrong(pred_list_b2_5x_10p, n=3)"
      ],
      "metadata": {
        "id": "YNjEYc4X9FIJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained.plot_N_most_wrong(pred_list_b0_5x_20p, n=3)"
      ],
      "metadata": {
        "id": "NC1TUjAx9Hjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained.plot_N_most_wrong(pred_list_b2_5x_20p, n=3)"
      ],
      "metadata": {
        "id": "Q-tDsbXo9J6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained.plot_N_most_wrong(pred_list_b0_10x_10p, n=3)"
      ],
      "metadata": {
        "id": "1n8UAaEn9MRM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained.plot_N_most_wrong(pred_list_b2_10x_10p, n=3)"
      ],
      "metadata": {
        "id": "uBBzN4rv9QUD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained.plot_N_most_wrong(pred_list_b0_10x_20p, n=3)"
      ],
      "metadata": {
        "id": "ebtCCmwS9TTM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained.plot_N_most_wrong(pred_list_b2_10x_20p, n=3)"
      ],
      "metadata": {
        "id": "SCS24dj69VlG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Image Links - top 3 worst predictions for EffNetB2 10 epochs 20% data:\n",
        "\n",
        "https://github.com/lanehale/pytorch-deep-learning/blob/main/06-output-images/b2_10x_20p_worst_prediction.png\n",
        "\n",
        "https://github.com/lanehale/pytorch-deep-learning/blob/main/06-output-images/b2_10x_20p_worst_prediction_2.png\n",
        "\n",
        "https://github.com/lanehale/pytorch-deep-learning/blob/main/06-output-images/b2_10x_20p_worst_prediction_3.png"
      ],
      "metadata": {
        "id": "NcsCxeo9uakY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models\n",
        "torch.save(obj=model_b2_10x_20p.state_dict(),\n",
        "           f=\"models/model_b2_10x_20p.pth\")\n",
        "!ls models"
      ],
      "metadata": {
        "id": "7j736YRYebfv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "model_b2_10x_20p.pth\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "kZpwO2T3tMXR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the best model locally to my machine\n",
        "from google.colab import files\n",
        "files.download(\"models/model_b2_10x_20p.pth\")"
      ],
      "metadata": {
        "id": "cQ8SyRs5c5GB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}