{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [
        {
          "file_id": "1y7JkyrO9hwmLorM58tyGWQ17loxcAbPE",
          "timestamp": 1760578268122
        },
        {
          "file_id": "1uLPLwAjgHJfgCxPtw4xwu5z_Wc3k1KBy",
          "timestamp": 1760571558944
        },
        {
          "file_id": "16ga4CDZcMieNcEtv_L0Gdv_SWQ1FD6h5",
          "timestamp": 1760563358922
        },
        {
          "file_id": "124_LOHjdliKY0jRfUIvdB1bHlGfxDFHb",
          "timestamp": 1752509551788
        },
        {
          "file_id": "1QPFYe4s6vfUCa5Q6TNBsBQy4uAMYecT-",
          "timestamp": 1752270073240
        }
      ],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyM1gpYaaVtggUvBicUo4qcO"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vBGXNiYqQEY_",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579107448,
          "user_tz": 360,
          "elapsed": 39758,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "9857821f-98a7-42ec-da8f-5047dd77e656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyarrow in /usr/local/lib/python3.12/dist-packages (18.1.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.57.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.6-py3-none-any.whl.metadata (9.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.20.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.12/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.10.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading evaluate-0.4.6-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.6\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n",
            "Collecting datasets\n",
            "  Downloading datasets-4.2.0-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets) (3.20.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n",
            "Collecting pyarrow>=21.0.0 (from datasets)\n",
            "  Downloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Requirement already satisfied: dill<0.4.1,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n",
            "Requirement already satisfied: httpx<1.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.28.1)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.6.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2025.9.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=0.25.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.35.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.3)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (3.13.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (4.11.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (2025.10.5)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1.0.0->datasets) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1.0.0->datasets) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=0.25.0->datasets) (1.1.10)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.9.0,>=2023.1.0->datasets) (1.22.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx<1.0.0->datasets) (1.3.1)\n",
            "Downloading datasets-4.2.0-py3-none-any.whl (506 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.3/506.3 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-21.0.0-cp312-cp312-manylinux_2_28_x86_64.whl (42.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 18.1.0\n",
            "    Uninstalling pyarrow-18.1.0:\n",
            "      Successfully uninstalled pyarrow-18.1.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 4.0.0\n",
            "    Uninstalling datasets-4.0.0:\n",
            "      Successfully uninstalled datasets-4.0.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\n",
            "pylibcudf-cu12 25.6.0 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-4.2.0 pyarrow-21.0.0\n"
          ]
        }
      ],
      "source": [
        "# Install HuggingFace libraries\n",
        "!pip install pyarrow\n",
        "!pip install transformers datasets evaluate\n",
        "!pip install -U datasets  # this prevents local cache errors with datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load dataset"
      ],
      "metadata": {
        "id": "3kZ0r_YbnkoQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the full dataset from HuggingFace. load_dataset combines all files in the\n",
        "# /train directory (without their headers) into one dataset with just one header.\n",
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer, DataCollatorWithPadding\n",
        "\n",
        "raw_datasets = load_dataset(\"lanehale1/airline-queries\", data_dir='train', cache_dir=None)\n",
        "raw_datasets"
      ],
      "metadata": {
        "id": "ny4JMNKlQ6RT",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579174174,
          "user_tz": 360,
          "elapsed": 21882,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373,
          "referenced_widgets": [
            "e9361dd2abb0484f981ad0913cbcc922",
            "29c20e66c0a9433e91b4332b774fee64",
            "897055c64707424d95eca12ce28aa3a9",
            "c98172b2c08b483c870cde30fa4f603d",
            "d7174d6ca1c14ccdb022d7c29ef399c9",
            "a8d6a2575f4549af8194f14e53c1057e",
            "5090a3e741fb43c6ac67adda13236fda",
            "579a988fa2314e9a8c89005ddf69f0bf",
            "5e3ca5ec22ff4c8a964d312c94a2095b",
            "3f61cbf453684f32a2634ce38ab20861",
            "021ed8f0d25742b59c8eb86749f9f219",
            "88384a03aebb470eac1d4b1d0f6b6692",
            "7922c3f918bb4d15bad1ca49c8e942bc",
            "b5e9f56effff488cba684035bbafc621",
            "c1494b60d8e248a397d5884b523ce508",
            "15d231577be24de3bffb162267627f12",
            "c793fdb3eec847e6831c7d8af291dc5a",
            "a6ea59a165684e60b2340477013dc0a4",
            "6a951e0c769045608722584b30765413",
            "adc8c6d9337b42e384d6a71e294b3155",
            "71666ef11d8b44469a5f16a8b14b7fb1",
            "5b13225d929643d7aaddaf874cd82cd9",
            "d627f6d995ea4e6097fce1175bc6ef99",
            "4ab19c5ec66549d0a5d44978266a51ad",
            "ba0b8ea12c7f454cb2f3081a4cc94501",
            "cbca3ed173da463b9158fc6e75824842",
            "76a162831c514eef8059e083ebe5b55a",
            "1c3428867352447c819b361e020d2ced",
            "93167ec9f4224b7c9433b5103c1b5cf6",
            "64a04e142413461b9acc9966f25b2de4",
            "2244a602aa594dd5bae5f763817b6fc2",
            "bf3672e3065948b5bd84aa961455f52e",
            "7201e63bcd04419ab6ceb0ea3336574b",
            "070c3331d5cc4a5892ca63f1046c10df",
            "5aa878fbc80544f39a25b8679358aa13",
            "1085b9ec90554e03a328b1bb678229ac",
            "907e52e1132f414684d0d62c583b6ea7",
            "59dd3ca127694f129de34ce1c0a73841",
            "e5b9085cb6ff42a3903741a73f080247",
            "656e922d62c24d2a87e8f3e849986ce6",
            "082e3c152e214aa083fb55dcb5603c36",
            "e8ec0259eeb1485f8c61a63500879bf6",
            "14f14c9075d1403b93e98bbe6f7a9c1a",
            "26363c1c22f142e7a68672cd53c0cd94"
          ]
        },
        "outputId": "3cd24576-e40a-4c3b-9bc1-c2b60bc6a8aa"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "query_intent_booking_altered.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9361dd2abb0484f981ad0913cbcc922"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "query_intent_general_altered.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "88384a03aebb470eac1d4b1d0f6b6692"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "query_intent_status_altered.csv: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d627f6d995ea4e6097fce1175bc6ef99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split: 0 examples [00:00, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "070c3331d5cc4a5892ca63f1046c10df"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['query', 'intent'],\n",
              "        num_rows: 1431\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the different classes ('intents')\n",
        "raw_datasets['train'][509:512], raw_datasets['train'][910:914]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q27Qr-1ilY2l",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579184955,
          "user_tz": 360,
          "elapsed": 68,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "8853c858-4919-42b8-aa18-0d74d4430c96"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'query': ['Could you book next month on the 21st St. Augustine to ALO',\n",
              "   'what luggage can I keep with me',\n",
              "   'Paducah flights are so cheap right now.'],\n",
              "  'intent': ['booking', 'general', 'general']},\n",
              " {'query': ['When will the YV agents arrive?',\n",
              "   'where do I pick up my stroller when getting off?',\n",
              "   'give the status of mq8139',\n",
              "   \"where's the terminal for 9E 9985?\"],\n",
              "  'intent': ['general', 'status', 'status', 'status']})"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets = load_dataset(\"lanehale1/airline-queries\", data_dir='train', cache_dir=None)"
      ],
      "metadata": {
        "id": "2Vw8a0287F1b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Change 'intent' labels to ClassLabel data type for the datasets library,\n",
        "# and split the dataset by class\n",
        "from datasets import ClassLabel, Value\n",
        "\n",
        "# Get the unique intents from the dataset\n",
        "unique_intents = raw_datasets['train'].unique('intent')\n",
        "\n",
        "# Define custom class names in the order corresponding to the integer labels\n",
        "custom_class_names = ['booking', 'general', 'status']\n",
        "\n",
        "# Cast the 'intent' column to ClassLabel with custom names\n",
        "raw_datasets['train'] = raw_datasets['train'].cast_column('intent', ClassLabel(names=custom_class_names))\n",
        "\n",
        "# Get the class labels\n",
        "class_label_names = raw_datasets['train'].features['intent'].names\n",
        "\n",
        "booking_idx = class_label_names.index('booking')\n",
        "general_idx = class_label_names.index('general')\n",
        "status_idx = class_label_names.index('status')\n",
        "\n",
        "print(booking_idx, general_idx, status_idx)\n",
        "# Create empty lists to store indices for each class\n",
        "indices_booking = []\n",
        "indices_general = []\n",
        "indices_status = []\n",
        "\n",
        "# Iterate through the dataset to collect indices for each class\n",
        "for i, example in enumerate(raw_datasets['train']):\n",
        "    if example['intent'] == booking_idx:\n",
        "        indices_booking.append(i)\n",
        "    elif example['intent'] == general_idx:\n",
        "        indices_general.append(i)\n",
        "    elif example['intent'] == status_idx:\n",
        "        indices_status.append(i)\n",
        "\n",
        "print(len(indices_booking), len(indices_general), len(indices_status))\n",
        "\n",
        "# Randomly select the desired number of indices for each class (try 70/15/15 splits)\n",
        "import random\n",
        "random.seed(13)\n",
        "indices_booking = random.sample(indices_booking, 356)\n",
        "indices_general = random.sample(indices_general, 281)\n",
        "indices_status = random.sample(indices_status, 364)\n",
        "\n",
        "# Combine the selected indices for the new training set\n",
        "train_indices = indices_booking + indices_general + indices_status\n",
        "\n",
        "# Create the new training dataset\n",
        "train_dataset = raw_datasets['train'].select(train_indices)\n",
        "\n",
        "# Get the remaining indices for the test set\n",
        "all_indices = list(range(len(raw_datasets['train'])))\n",
        "test_indices = list(set(all_indices) - set(train_indices))\n",
        "\n",
        "# Create the new test dataset\n",
        "temp_dataset = raw_datasets['train'].select(test_indices)\n",
        "\n",
        "train_dataset, temp_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223,
          "referenced_widgets": [
            "1d6633d1e41d43bd95785592dc7e337e",
            "564639a5e9d144d984628eaea1c8afaa",
            "35668780dc7c409c80d0fb15c05e8069",
            "46f32375b9db47bdae3da14fe7585d27",
            "a773acc4efb94eaf848c5eb22c388053",
            "7c68b7e8d24843a2ba464102dc17aac0",
            "a773658b525541f096db9b5a968cddaa",
            "c831370a3760416d947244eaa257b9d5",
            "fd089ddf3ee54a0681d3ea39e1f28f11",
            "19ad21066beb43fa888d27dddf4963c4",
            "97b1031f7c9e4d4d907ea4498686f1a0"
          ]
        },
        "id": "24QjinpewHqh",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579188613,
          "user_tz": 360,
          "elapsed": 322,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "e3c5f87c-6dac-4c26-ae99-945aaa378316"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting the dataset:   0%|          | 0/1431 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d6633d1e41d43bd95785592dc7e337e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 1 2\n",
            "510 401 520\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['query', 'intent'],\n",
              "     num_rows: 1001\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['query', 'intent'],\n",
              "     num_rows: 430\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "temp_indices_booking = []\n",
        "temp_indices_general = []\n",
        "temp_indices_status = []\n",
        "\n",
        "for i, example in enumerate(temp_dataset):\n",
        "    if example['intent'] == booking_idx:\n",
        "        temp_indices_booking.append(i)\n",
        "    elif example['intent'] == general_idx:\n",
        "        temp_indices_general.append(i)\n",
        "    elif example['intent'] == status_idx:\n",
        "        temp_indices_status.append(i)\n",
        "\n",
        "# Randomly select the desired number of indices for each class\n",
        "import random\n",
        "random.seed(13)\n",
        "temp_indices_booking = random.sample(temp_indices_booking, 154)\n",
        "temp_indices_general = random.sample(temp_indices_general, 120)\n",
        "temp_indices_status = random.sample(temp_indices_status, 156)\n",
        "\n",
        "eval_indices_booking = temp_indices_booking[:77]\n",
        "eval_indices_general = temp_indices_general[:60]\n",
        "eval_indices_status = temp_indices_status[:78]\n",
        "\n",
        "test_indices_booking = temp_indices_booking[77:]\n",
        "test_indices_general = temp_indices_general[60:]\n",
        "test_indices_status = temp_indices_status[78:]\n",
        "\n",
        "print(len(eval_indices_booking), len(eval_indices_general), len(eval_indices_status))\n",
        "print(len(test_indices_booking), len(test_indices_general), len(test_indices_status))\n",
        "# Combine the selected indices for the validation set\n",
        "eval_indices = eval_indices_booking + eval_indices_general + eval_indices_status\n",
        "\n",
        "# Create the validation dataset\n",
        "eval_dataset = raw_datasets['train'].select(eval_indices)\n",
        "\n",
        "# Combine the selected indices for the test set\n",
        "test_indices = test_indices_booking + test_indices_general + test_indices_status\n",
        "\n",
        "# Create the test dataset\n",
        "test_dataset = raw_datasets['train'].select(test_indices)\n",
        "\n",
        "eval_dataset, test_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4DgpEsddbLR",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579199251,
          "user_tz": 360,
          "elapsed": 86,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "6b1e5d44-fcad-44f2-9151-3085bdc0d9b1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "77 60 78\n",
            "77 60 78\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Dataset({\n",
              "     features: ['query', 'intent'],\n",
              "     num_rows: 215\n",
              " }),\n",
              " Dataset({\n",
              "     features: ['query', 'intent'],\n",
              "     num_rows: 215\n",
              " }))"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save train, validation, and test datasets in raw_datasets\n",
        "raw_datasets['train'] = train_dataset\n",
        "raw_datasets['validation'] = eval_dataset\n",
        "raw_datasets['test'] = test_dataset\n",
        "raw_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y4Lw83zA0-K9",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579203158,
          "user_tz": 360,
          "elapsed": 30,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "e1eb7cc6-a555-4c6e-de86-14f91518d4e4"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['query', 'intent'],\n",
              "        num_rows: 1001\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['query', 'intent'],\n",
              "        num_rows: 215\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['query', 'intent'],\n",
              "        num_rows: 215\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define checkpoint and tokenizer\n",
        "checkpoint = \"bert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "\n",
        "def tokenize_function(example):\n",
        "    return tokenizer(example[\"query\"], truncation=True)\n",
        "\n",
        "# Create tokenized_datasets and data_collator\n",
        "tokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\n",
        "data_collator = DataCollatorWithPadding(tokenizer=tokenizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241,
          "referenced_widgets": [
            "a17845e90f874af696ab885347ec26c6",
            "fee4e8bc649c48b2a4543c76aa833bf3",
            "4cc2b5ca94a94bbf91e150a7d9082537",
            "c3fb758d006f43a98054babc17601787",
            "2e1d5284913a4c7cbafbfbf563e0f746",
            "77128b9350c743369124e8e9127ea51e",
            "696726fc97e74b6189a8eaf0d0b27a77",
            "651f1c037d3f4c5da2cb8bd6bf7bc48e",
            "bb68a65d8ebe49b6b8358f4c3e840416",
            "b1558230338648668b9390751d2eeca0",
            "fa26228bf53342aeafa212e3eac47a6e",
            "734277df281545998f3c5b214c0addcc",
            "b47a4bfa1ab1428f9393011b4ad681f4",
            "4c98f8cfa86c4928b39b7b3ea963861a",
            "79db6a50e8e04262b16e47ff612e9a57",
            "a69e017611914ba9951358b19e41cb34",
            "5b197bd40c924ff980ba709edd95e71a",
            "d73c3ca9d71b49f693437b4119f909ee",
            "46686690a3d0435ebcb756f97fa157f8",
            "0bccc12702ac435c944d07376407ebd6",
            "7a567208d108441097077310910e033f",
            "1e5cc6cefc1e433394aab4fab7545f97",
            "427cc256bb8f4510a412303831758334",
            "07e654b9c23b433b80ec8024d7f326da",
            "075724e058f74f53a13a5fe653203cf8",
            "5de3c2c94fda4a78a53db4c8867f5322",
            "e1eb11ecb9444ca6944f92e283a47bf0",
            "4a160e10725d44829d2b78c24af1e862",
            "d86aa009c1574522956d2c1b85640d9f",
            "4439af2b33a94a38874410d567f6568c",
            "2728f51ac680478a9d5f2289ee83d9ee",
            "3f11bafb71ef4b62966d630c4073d1c0",
            "0cccd861a0c94a428562e6dfbb3a58ad",
            "01ff9fe9cf5e4f199f38c3a128b12471",
            "f7116cffc76841778a469ca47449ac26",
            "956195ec01cb42e2a1076d2cb3655750",
            "35ecba86cabd411f917db4d4aca37f07",
            "de3b6a1458c640dcb99c5211920aa72a",
            "27dc69c4b1c844b9bf179dec8d2651a1",
            "f5ee32c0d57d4d4e81c76283375d86a8",
            "436a4f75338a40118eb0f0d3f229c943",
            "561e21e2c5664db6a9e703b1dce44e98",
            "2c2430534e694f609e55351838ff72c2",
            "6e82565c6d964ac78785ae4da03be32d",
            "9117ecc78480429e82c1c2c9921cfc95",
            "aea56a57c92a457a905cc302c877ad42",
            "995acd6e36854b688d8a1fd3f7b8966a",
            "c4f0c888d93d42d6be7c4353ab309a16",
            "4c01eef8e77547ebbd430f245efae025",
            "e19c723faad3417d84c093d40a71bb9a",
            "603c0dd1c0c246de86a04962ab3e9a2e",
            "f9e7fee5eeea41239696b4effc5abd27",
            "3e6d67cf971d4c20923df44bba9cbdb8",
            "c39e946d020243ac9e2f939c906ccf3f",
            "48ac38f404d1477eb6c8ec3ea9f85d36",
            "61db80dbd1434763be165b2b862efa82",
            "16f20288ac424986ae54f712e8a77fe2",
            "efe261c700654f5b8818eac7d4dd43e4",
            "3287ab3f942b415c8e2730c517b84305",
            "d150015e1c9d4392977fa519f4f64b24",
            "7160526d63394b35bd471e5d6e001e87",
            "e5df950aade048d68c3ab974a75e62df",
            "5dc3da91d8314f11bb4ba9d1ca4a4edf",
            "56b7c733e1cd4399bb5cfdc4e14ea3d3",
            "f8477df7a2694a8d95245ef3c3d9938a",
            "ea6af5264764494fb2c8f4162e0af2f1",
            "cd307df5027645ff847e8157eea3f997",
            "3777cc1663734474a0802ac79f097dc8",
            "44bfffaad8324f71a14d446cf5968797",
            "68f02134c23242fc8d7f4cdda3cf636a",
            "ed1926e25c9b4c01b3a125534e2ab77e",
            "b8a2688df13342aba91c21a6364e4f91",
            "5108824ec90c4a5790a4965248dc06ec",
            "4582162eaee644258c699f3a670aed81",
            "77d69245e699487385898fd6fb023b10",
            "44836d182fce43a5964aebefcf62f650",
            "a920c0a0e2134bf4ad7f981cedfd8c96"
          ]
        },
        "id": "ht8ZKFLLhulf",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579209185,
          "user_tz": 360,
          "elapsed": 2114,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "aa75eb6b-5318-4b66-b3a3-6412ff3de748"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a17845e90f874af696ab885347ec26c6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "734277df281545998f3c5b214c0addcc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "427cc256bb8f4510a412303831758334"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "01ff9fe9cf5e4f199f38c3a128b12471"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/1001 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9117ecc78480429e82c1c2c9921cfc95"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/215 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "61db80dbd1434763be165b2b862efa82"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/215 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cd307df5027645ff847e8157eea3f997"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display tokenized_datasets\n",
        "tokenized_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5gFASF3R2rD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579214301,
          "user_tz": 360,
          "elapsed": 16,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "27a180eb-72d7-49ca-9167-5756ff23d690"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['query', 'intent', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 1001\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['query', 'intent', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 215\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['query', 'intent', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              "        num_rows: 215\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a sample from train dataset\n",
        "raw_datasets[\"train\"][1], tokenized_datasets[\"train\"][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N0EkaRThZXqb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579217760,
          "user_tz": 360,
          "elapsed": 50,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "a336dccb-9cdb-46ee-9c08-e892c51618c8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'query': 'Book anything PIE - JST on 12/26/25', 'intent': 0},\n",
              " {'query': 'Book anything PIE - JST on 12/26/25',\n",
              "  'intent': 0,\n",
              "  'input_ids': [101,\n",
              "   2338,\n",
              "   2505,\n",
              "   11345,\n",
              "   1011,\n",
              "   1046,\n",
              "   3367,\n",
              "   2006,\n",
              "   2260,\n",
              "   1013,\n",
              "   2656,\n",
              "   1013,\n",
              "   2423,\n",
              "   102],\n",
              "  'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]})"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a sample from validation dataset\n",
        "raw_datasets[\"validation\"][1], tokenized_datasets[\"validation\"][1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MbIy8L4fEeI",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579222055,
          "user_tz": 360,
          "elapsed": 40,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "a354e03f-517e-46f9-ca6b-d6b6adbaf12c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'query': 'Find a late flight Butte Garden City the 13th of next month',\n",
              "  'intent': 0},\n",
              " {'query': 'Find a late flight Butte Garden City the 13th of next month',\n",
              "  'intent': 0,\n",
              "  'input_ids': [101,\n",
              "   2424,\n",
              "   1037,\n",
              "   2397,\n",
              "   3462,\n",
              "   25024,\n",
              "   3871,\n",
              "   2103,\n",
              "   1996,\n",
              "   6122,\n",
              "   1997,\n",
              "   2279,\n",
              "   3204,\n",
              "   102],\n",
              "  'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]})"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display a sample from test dataset\n",
        "raw_datasets['test'][0], tokenized_datasets['test'][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YlSXJkPIl9Mb",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579225946,
          "user_tz": 360,
          "elapsed": 33,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "9fc26c05-8cc0-4437-8592-4ed1ca0e0eac"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'query': 'Find a OTH-MIA flight 7-26 p.m.', 'intent': 0},\n",
              " {'query': 'Find a OTH-MIA flight 7-26 p.m.',\n",
              "  'intent': 0,\n",
              "  'input_ids': [101,\n",
              "   2424,\n",
              "   1037,\n",
              "   27178,\n",
              "   2232,\n",
              "   1011,\n",
              "   8764,\n",
              "   3462,\n",
              "   1021,\n",
              "   1011,\n",
              "   2656,\n",
              "   1052,\n",
              "   1012,\n",
              "   1049,\n",
              "   1012,\n",
              "   102],\n",
              "  'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "  'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove unnecessary columns\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"query\"])\n",
        "# Rename ClassLabel column to 'labels'\n",
        "tokenized_datasets = tokenized_datasets.rename_column(\"intent\", \"labels\")\n",
        "# Set output type to 'torch'\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "# Display modified datasets\n",
        "tokenized_datasets[\"train\"].column_names, tokenized_datasets[\"validation\"].column_names, tokenized_datasets[\"test\"].column_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n_IoBHIoRbS7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579231315,
          "user_tz": 360,
          "elapsed": 33,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "e02ba6c7-0ffa-40f4-dc44-112a1a163ebf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              " ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
              " ['labels', 'input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and eval dataloaders\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"train\"], shuffle=True, batch_size=16, collate_fn=data_collator\n",
        ")\n",
        "eval_dataloader = DataLoader(\n",
        "    tokenized_datasets[\"validation\"], batch_size=16, collate_fn=data_collator\n",
        ")\n",
        "len(train_dataloader), len(eval_dataloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1rW3Hwawf9su",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579233912,
          "user_tz": 360,
          "elapsed": 15,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "4d7b8697-3424-4a71-ffe9-247773e62791"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(63, 14)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the shape of a training batch\n",
        "for batch in train_dataloader:\n",
        "    break\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hXuCfEa2hOnd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579236034,
          "user_tz": 360,
          "elapsed": 31,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "952af9a6-06ce-412d-ba79-486a89f117a2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': torch.Size([16]),\n",
              " 'input_ids': torch.Size([16, 15]),\n",
              " 'token_type_ids': torch.Size([16, 15]),\n",
              " 'attention_mask': torch.Size([16, 15])}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the shape of a validation batch\n",
        "for batch in eval_dataloader:\n",
        "  break\n",
        "{k: v.shape for k, v in batch.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6gYZziyhZkh",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579237755,
          "user_tz": 360,
          "elapsed": 14,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "7068fb15-afcd-4abd-b18b-bc963779e440"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': torch.Size([16]),\n",
              " 'input_ids': torch.Size([16, 17]),\n",
              " 'token_type_ids': torch.Size([16, 17]),\n",
              " 'attention_mask': torch.Size([16, 17])}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a model\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=3, problem_type=\"single_label_classification\")  # 3 intents\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885,
          "referenced_widgets": [
            "1fa18877bb154792930a9c87ccc83f77",
            "ffbf1e87a6d5413cb8b2ee2169437e82",
            "8d9bb6f469e8460a9e993b860db85fbc",
            "e8ee4efe02be4d6b895a9a67851726d9",
            "cf9c47b21273412eb6ef7622c7bfe3da",
            "cc37a38c4e8c4442888225543a32efe1",
            "d21d34cdac84430b87c80a03df6079e2",
            "32c2ab6a547246da98ea8fee9f8793e3",
            "2af9c4ad8a744eb0b7feb760d773b9cb",
            "e8172a38670b49c49554072de7cf35f8",
            "20b285c4fd9647ba8e8d301a3bbffe38"
          ]
        },
        "id": "UKjgCBvw01nc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579249594,
          "user_tz": 360,
          "elapsed": 8602,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "ab663e0d-a30a-49b0-88e7-ad4607e1290c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1fa18877bb154792930a9c87ccc83f77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSdpaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8842facc",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579261277,
          "user_tz": 360,
          "elapsed": 648,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "0b345269-05bd-4339-ff1e-1b9f5975e2e1"
      },
      "source": [
        "\"\"\"\n",
        "The batch variable is a Python dictionary containing various inputs required by the model.\n",
        "\n",
        "The **batch syntax unpacks this dictionary, treating each key-value pair as a keyword argument to be\n",
        "passed to the model's forward method (which is implicitly called when you call model(...) directly).\n",
        "\n",
        "The double asterisk (**) in outputs = model(**batch) is the dictionary unpacking operator.\n",
        "\"\"\"\n",
        "# Display batch loss parameter and logits shape\n",
        "outputs = model(**batch)\n",
        "print(outputs.loss, outputs.logits.shape)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(1.1445, grad_fn=<NllLossBackward0>) torch.Size([16, 3])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the batch keys\n",
        "print(list(batch.keys()))\n",
        "# Display all batch data\n",
        "batch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7tq19nurUVYS",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579265310,
          "user_tz": 360,
          "elapsed": 44,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "d8d84c50-ed34-4e4d-df06-ae0bbdfaff0b"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['labels', 'input_ids', 'token_type_ids', 'attention_mask']\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'labels': tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]), 'input_ids': tensor([[  101,  2424,  1037,  1048,  3366,  1011,  1061,  3070,  4440,  2005,\n",
              "          1018,  1011,  2570,  2397,   102,     0,     0],\n",
              "        [  101,  2424,  1037,  2397,  3462, 25024,  3871,  2103,  1996,  6122,\n",
              "          1997,  2279,  3204,   102,     0,     0,     0],\n",
              "        [  101,  2424,  1037,  4540,  1011,  2065,  2361,  3462,  1019,  1011,\n",
              "          2861,  7610,   102,     0,     0,     0,     0],\n",
              "        [  101,  2106,  2017,  2424,  2505,  2279,  3204,  2006,  1996,  5940,\n",
              "          5578,  2000,  2522,  2015,  1029,   102,     0],\n",
              "        [  101,  2338, 24829,  2050,  2000, 21469,  2232,   102,     0,     0,\n",
              "             0,     0,     0,     0,     0,     0,     0],\n",
              "        [  101,  6134,  2250,  6494,  2078,  2358,  2140,  1011,  2030,  2232,\n",
              "           102,     0,     0,     0,     0,     0,     0],\n",
              "        [  101,  3914,  2142,  9587,  4179,  1011, 11577,  2005,  9317,   102,\n",
              "             0,     0,     0,     0,     0,     0,     0],\n",
              "        [  101,  2156,  2065,  1045,  2064,  4875,  2041,  2006,  4943,  5401,\n",
              "          2620,  2487,   102,     0,     0,     0,     0],\n",
              "        [  101,  6134,  5292,  1058,  6392,  1011, 19842,  2100,  2005,  2048,\n",
              "          4268,  1010,  5535,  2184,  1998,  2410,   102],\n",
              "        [  101,  6134,  2137,  6755, 20294,  2692,  2005,  4826,  2305,   102,\n",
              "             0,     0,     0,     0,     0,     0,     0],\n",
              "        [  101,  3046,  4531,  2019,  2800,  3462,  4826, 13430,  2271,  2000,\n",
              "          5865,   102,     0,     0,     0,     0,     0],\n",
              "        [  101,  2026,  4268,  2215,  2000,  2272,  2013,  2605,  1999,  2238,\n",
              "           102,     0,     0,     0,     0,     0,     0],\n",
              "        [  101,  3914,  2552,  1011, 22214,  2226,  2005,  1023,  1013,  2340,\n",
              "          1013,  2656,   102,     0,     0,     0,     0],\n",
              "        [  101,  2424,  2019,  2220,  3462, 11333,  3597,  2000, 16897,  2102,\n",
              "         26261,  1012,  5032,   102,     0,     0,     0],\n",
              "        [  101,  3914,  2358,  2278,  1011,  1043,  3600,  1016,  1011,  2410,\n",
              "          1037,  1012,  1049,  1012,   102,     0,     0],\n",
              "        [  101,  2071,  2017,  6134,  2279,  3204,  2006,  1996,  3083,  6278,\n",
              "          2000,  7987,  2094,   102,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
              "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0]])}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display all of unpacked batch 'outputs'\n",
        "outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SQ7xaBKjTQHj",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579270266,
          "user_tz": 360,
          "elapsed": 38,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "c1c404f3-f94d-4e9c-edbb-6eac4646fe18"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SequenceClassifierOutput(loss=tensor(1.1445, grad_fn=<NllLossBackward0>), logits=tensor([[ 0.0573,  0.0647,  0.0512],\n",
              "        [ 0.0570,  0.0413,  0.1305],\n",
              "        [ 0.0790,  0.0366,  0.0765],\n",
              "        [ 0.0869,  0.0883,  0.0924],\n",
              "        [-0.2381,  0.1290,  0.0513],\n",
              "        [ 0.0740,  0.1719,  0.0610],\n",
              "        [ 0.0281,  0.0353, -0.0110],\n",
              "        [-0.0549,  0.1097,  0.1494],\n",
              "        [ 0.1174,  0.1425,  0.0107],\n",
              "        [-0.1447,  0.1397,  0.1470],\n",
              "        [ 0.0990,  0.0369,  0.0905],\n",
              "        [-0.0825,  0.1221,  0.1455],\n",
              "        [ 0.1808,  0.1549,  0.0481],\n",
              "        [ 0.0853,  0.1020,  0.0541],\n",
              "        [ 0.1453,  0.1946,  0.0780],\n",
              "        [-0.0797,  0.0452,  0.1111]], grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use HuggingFace Trainer"
      ],
      "metadata": {
        "id": "1F7S2K9tGtwi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\" Set up training arguments \"\"\"\n",
        "import numpy as np\n",
        "from evaluate import load\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "\n",
        "# 1. Load accuracy and f1 metrics\n",
        "acc_metric = load(\"accuracy\")\n",
        "f1_metric = load(\"f1\")\n",
        "\n",
        "# 2. Define a compute_metrics function\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = logits.argmax(axis=-1)\n",
        "    accuracy = acc_metric.compute(predictions=predictions, references=labels)\n",
        "    f1 = f1_metric.compute(predictions=predictions, references=labels, average=\"weighted\")\n",
        "    return {\"accuracy\": accuracy[\"accuracy\"], \"f1\": f1[\"f1\"]}  # Return a dictionary as expected by Trainer\n",
        "\n",
        "# Get default training arguments to decide what to use\n",
        "training_args = TrainingArguments()\n",
        "\n",
        "# Total Training Steps = (Dataset Size / (per_device_train_batch_size * gradient_accumulation_steps)) * num_train_epoch\n",
        "total_training_steps = (\n",
        "    len(tokenized_datasets[\"train\"]) /\n",
        "    (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps)\n",
        "    * training_args.num_train_epochs\n",
        ")\n",
        "\n",
        "[len(tokenized_datasets[\"train\"]),\n",
        " training_args.per_device_train_batch_size,\n",
        " training_args.gradient_accumulation_steps,\n",
        " training_args.num_train_epochs,\n",
        " total_training_steps,\n",
        " training_args.learning_rate,\n",
        " training_args.weight_decay,\n",
        " training_args.warmup_ratio,\n",
        "]"
      ],
      "metadata": {
        "id": "iaBjUP8xDvya",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579279995,
          "user_tz": 360,
          "elapsed": 6318,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 98,
          "referenced_widgets": [
            "c5ecf39c7d2740d392a63dcb4fd330f8",
            "b37802a1cd3540878820e220e3ec1aca",
            "4b289712274a4c519f2e47508c929825",
            "1847407aae594e7d88d9ed62b100eeec",
            "ba451c77ceb04b36b4af09a4f325de97",
            "25e1f0dcf04741b1a75ff19767477780",
            "47c9ba5e06f54a609b77b43d2cd9694b",
            "1f245178f81f43749391096fd6943229",
            "b04ec572571d44da973f963ddefbbc89",
            "ff45da7022d04acab9a5ea27cda5e730",
            "8498080af7cc4c56947ae403d2af5b88",
            "6fc44d80ef01490d9feb347cc7f76b93",
            "d33b3683da2f400f9d0444ae1c6a7dd9",
            "514b7f98ec62414aab237320422e7461",
            "76067e970eb042baa0fa54e6f2197f34",
            "732669632ed34b8c80c023e9a70bc7e1",
            "d857a8b68906445a9c4c00fe3fa8a884",
            "90290e1f70394cf28494bf94f77b3695",
            "f2f665d428314f6d81e6287f8f5cd755",
            "fcd75801be9c496e91cfaf78e5bb67a0",
            "2ecdf1e9f6a943c1807f1c976c70e405",
            "8f13b863e5694412955d5093391d8c25"
          ]
        },
        "outputId": "65a415d2-a399-4b40-f366-49c300f137d9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c5ecf39c7d2740d392a63dcb4fd330f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script: 0.00B [00:00, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6fc44d80ef01490d9feb347cc7f76b93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1001, 8, 1, 3.0, 375.375, 5e-05, 0.0, 0.0]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Round steps per epoch in case division by batch size is fractional\n",
        "steps_per_epoch = round(len(tokenized_datasets[\"train\"]) / (training_args.per_device_train_batch_size * training_args.gradient_accumulation_steps), 0)\n",
        "num_epochs = training_args.num_train_epochs\n",
        "total_training_steps = steps_per_epoch * num_epochs\n",
        "\n",
        "print(f\"Steps per epoch (rounded): {steps_per_epoch} * {num_epochs} train epochs = {total_training_steps} training steps\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-3a1WWEk58V",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579287382,
          "user_tz": 360,
          "elapsed": 50,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "7938aaed-325d-408d-bcc1-05f24e483747"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Steps per epoch (rounded): 125.0 * 3.0 train epochs = 375.0 training steps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./model_results\",\n",
        "    run_name='airline-chatbot-model',\n",
        "    eval_strategy=\"steps\",\n",
        "    eval_steps=5,\n",
        "    save_steps=5,       # Save a model checkpoint every 5 steps\n",
        "    logging_steps=5,    # Log metrics every 5 steps\n",
        "    learning_rate=2e-5,\n",
        "    weight_decay=0.01,  # Weight decay (also known as L2 regularization) is a regularization technique that penalizes large weights in the model. It essentially adds a term to the loss function that is proportional to the square of the weights, encouraging the model to learn smaller, more generalized weights.\n",
        "    warmup_ratio=0.1,   # Warmup refers to a strategy where the learning rate gradually increases from a very small value (often close to zero) to the initial learning rate over a specified number of training steps. Stabilizes training, helps escape poor initializations, reduces early overfitting.\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    report_to=\"wandb\",  # Send logs to Weights & Biases\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"eval_loss\",\n",
        "    greater_is_better=False,\n",
        "    # Keep only the last and best checkpoint\n",
        "    save_total_limit=2\n",
        ")\n",
        "\n",
        "training_args"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1iJ0UBNlSC8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579302351,
          "user_tz": 360,
          "elapsed": 54,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "0c5da55c-b396-41f1-de81-2389d05d3a79"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainingArguments(\n",
              "_n_gpu=1,\n",
              "accelerator_config={'split_batches': False, 'dispatch_batches': None, 'even_batches': True, 'use_seedable_sampler': True, 'non_blocking': False, 'gradient_accumulation_kwargs': None, 'use_configured_state': False},\n",
              "adafactor=False,\n",
              "adam_beta1=0.9,\n",
              "adam_beta2=0.999,\n",
              "adam_epsilon=1e-08,\n",
              "auto_find_batch_size=False,\n",
              "average_tokens_across_devices=True,\n",
              "batch_eval_metrics=False,\n",
              "bf16=False,\n",
              "bf16_full_eval=False,\n",
              "data_seed=None,\n",
              "dataloader_drop_last=False,\n",
              "dataloader_num_workers=0,\n",
              "dataloader_persistent_workers=False,\n",
              "dataloader_pin_memory=True,\n",
              "dataloader_prefetch_factor=None,\n",
              "ddp_backend=None,\n",
              "ddp_broadcast_buffers=None,\n",
              "ddp_bucket_cap_mb=None,\n",
              "ddp_find_unused_parameters=None,\n",
              "ddp_timeout=1800,\n",
              "debug=[],\n",
              "deepspeed=None,\n",
              "disable_tqdm=False,\n",
              "do_eval=True,\n",
              "do_predict=False,\n",
              "do_train=False,\n",
              "eval_accumulation_steps=None,\n",
              "eval_delay=0,\n",
              "eval_do_concat_batches=True,\n",
              "eval_on_start=False,\n",
              "eval_steps=5,\n",
              "eval_strategy=IntervalStrategy.STEPS,\n",
              "eval_use_gather_object=False,\n",
              "fp16=False,\n",
              "fp16_backend=auto,\n",
              "fp16_full_eval=False,\n",
              "fp16_opt_level=O1,\n",
              "fsdp=[],\n",
              "fsdp_config={'min_num_params': 0, 'xla': False, 'xla_fsdp_v2': False, 'xla_fsdp_grad_ckpt': False},\n",
              "fsdp_min_num_params=0,\n",
              "fsdp_transformer_layer_cls_to_wrap=None,\n",
              "full_determinism=False,\n",
              "gradient_accumulation_steps=1,\n",
              "gradient_checkpointing=False,\n",
              "gradient_checkpointing_kwargs=None,\n",
              "greater_is_better=False,\n",
              "group_by_length=False,\n",
              "half_precision_backend=auto,\n",
              "hub_always_push=False,\n",
              "hub_model_id=None,\n",
              "hub_private_repo=None,\n",
              "hub_revision=None,\n",
              "hub_strategy=HubStrategy.EVERY_SAVE,\n",
              "hub_token=<HUB_TOKEN>,\n",
              "ignore_data_skip=False,\n",
              "include_for_metrics=[],\n",
              "include_inputs_for_metrics=False,\n",
              "include_num_input_tokens_seen=no,\n",
              "include_tokens_per_second=False,\n",
              "jit_mode_eval=False,\n",
              "label_names=None,\n",
              "label_smoothing_factor=0.0,\n",
              "learning_rate=2e-05,\n",
              "length_column_name=length,\n",
              "liger_kernel_config=None,\n",
              "load_best_model_at_end=True,\n",
              "local_rank=0,\n",
              "log_level=passive,\n",
              "log_level_replica=warning,\n",
              "log_on_each_node=True,\n",
              "logging_dir=./model_results/runs/Oct16_01-48-22_085f63170bff,\n",
              "logging_first_step=False,\n",
              "logging_nan_inf_filter=True,\n",
              "logging_steps=5,\n",
              "logging_strategy=IntervalStrategy.STEPS,\n",
              "lr_scheduler_kwargs={},\n",
              "lr_scheduler_type=SchedulerType.LINEAR,\n",
              "max_grad_norm=1.0,\n",
              "max_steps=-1,\n",
              "metric_for_best_model=eval_loss,\n",
              "mp_parameters=,\n",
              "neftune_noise_alpha=None,\n",
              "no_cuda=False,\n",
              "num_train_epochs=3,\n",
              "optim=OptimizerNames.ADAMW_TORCH_FUSED,\n",
              "optim_args=None,\n",
              "optim_target_modules=None,\n",
              "output_dir=./model_results,\n",
              "overwrite_output_dir=False,\n",
              "parallelism_config=None,\n",
              "past_index=-1,\n",
              "per_device_eval_batch_size=8,\n",
              "per_device_train_batch_size=8,\n",
              "prediction_loss_only=False,\n",
              "project=huggingface,\n",
              "push_to_hub=False,\n",
              "push_to_hub_model_id=None,\n",
              "push_to_hub_organization=None,\n",
              "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
              "ray_scope=last,\n",
              "remove_unused_columns=True,\n",
              "report_to=['wandb'],\n",
              "restore_callback_states_from_checkpoint=False,\n",
              "resume_from_checkpoint=None,\n",
              "run_name=airline-chatbot-model,\n",
              "save_on_each_node=False,\n",
              "save_only_model=False,\n",
              "save_safetensors=True,\n",
              "save_steps=5,\n",
              "save_strategy=SaveStrategy.STEPS,\n",
              "save_total_limit=2,\n",
              "seed=42,\n",
              "skip_memory_metrics=True,\n",
              "tf32=None,\n",
              "torch_compile=False,\n",
              "torch_compile_backend=None,\n",
              "torch_compile_mode=None,\n",
              "torch_empty_cache_steps=None,\n",
              "torchdynamo=None,\n",
              "tpu_metrics_debug=False,\n",
              "tpu_num_cores=None,\n",
              "trackio_space_id=trackio,\n",
              "use_cpu=False,\n",
              "use_legacy_prediction_loop=False,\n",
              "use_liger_kernel=False,\n",
              "use_mps_device=False,\n",
              "warmup_ratio=0.1,\n",
              "warmup_steps=0,\n",
              "weight_decay=0.01,\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EarlyStoppingCallback\n",
        "\n",
        "early_stopping = EarlyStoppingCallback(early_stopping_patience=3)"
      ],
      "metadata": {
        "id": "zY6VTufEFXW6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579308567,
          "user_tz": 360,
          "elapsed": 36,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        }
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Define a trainer\n",
        "from transformers import Trainer\n",
        "\n",
        "trainer = Trainer(\n",
        "    model,\n",
        "    training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    data_collator=data_collator,\n",
        "    processing_class=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[early_stopping],\n",
        ")\n",
        "\n",
        "trainer"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06YFKEQkFIlY",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579310175,
          "user_tz": 360,
          "elapsed": 134,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "ba35508b-ad02-47f5-d258-4b65b101f72d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<transformers.trainer.Trainer at 0x7906700b5d60>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nYkpdoESGD8o",
        "outputId": "a6d3b2a8-18ec-4944-eae0-d5d51e976ee8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579813231,
          "user_tz": 360,
          "elapsed": 498392,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/notebook/notebookapp.py:191: SyntaxWarning: invalid escape sequence '\\/'\n",
            "  | |_| | '_ \\/ _` / _` |  _/ -_)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize?ref=models\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mlanehale1\u001b[0m (\u001b[33mlanehale1-ai\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251016_014845-vop2pah9</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lanehale1-ai/huggingface/runs/vop2pah9' target=\"_blank\">airline-chatbot-model</a></strong> to <a href='https://wandb.ai/lanehale1-ai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lanehale1-ai/huggingface' target=\"_blank\">https://wandb.ai/lanehale1-ai/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lanehale1-ai/huggingface/runs/vop2pah9' target=\"_blank\">https://wandb.ai/lanehale1-ai/huggingface/runs/vop2pah9</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='145' max='378' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [145/378 08:05 < 13:11, 0.29 it/s, Epoch 1/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.095900</td>\n",
              "      <td>1.109364</td>\n",
              "      <td>0.358140</td>\n",
              "      <td>0.527397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>1.091100</td>\n",
              "      <td>1.044319</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.837838</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>1.064900</td>\n",
              "      <td>0.954710</td>\n",
              "      <td>0.962791</td>\n",
              "      <td>0.981043</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>1.051300</td>\n",
              "      <td>0.874191</td>\n",
              "      <td>0.981395</td>\n",
              "      <td>0.990610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>1.004700</td>\n",
              "      <td>0.757064</td>\n",
              "      <td>0.981395</td>\n",
              "      <td>0.990610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.989800</td>\n",
              "      <td>0.734912</td>\n",
              "      <td>0.902326</td>\n",
              "      <td>0.948655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.902800</td>\n",
              "      <td>0.702198</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.883117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.819100</td>\n",
              "      <td>0.391456</td>\n",
              "      <td>0.981395</td>\n",
              "      <td>0.990610</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.803300</td>\n",
              "      <td>0.322122</td>\n",
              "      <td>0.986047</td>\n",
              "      <td>0.992974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.737100</td>\n",
              "      <td>0.324100</td>\n",
              "      <td>0.976744</td>\n",
              "      <td>0.988235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.762700</td>\n",
              "      <td>0.363629</td>\n",
              "      <td>0.944186</td>\n",
              "      <td>0.971292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.669000</td>\n",
              "      <td>0.304027</td>\n",
              "      <td>0.958140</td>\n",
              "      <td>0.978622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>65</td>\n",
              "      <td>0.617500</td>\n",
              "      <td>0.230973</td>\n",
              "      <td>0.986047</td>\n",
              "      <td>0.992974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>70</td>\n",
              "      <td>0.509900</td>\n",
              "      <td>0.186013</td>\n",
              "      <td>0.990698</td>\n",
              "      <td>0.995327</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>75</td>\n",
              "      <td>0.474500</td>\n",
              "      <td>0.155111</td>\n",
              "      <td>0.986047</td>\n",
              "      <td>0.992974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>80</td>\n",
              "      <td>0.493100</td>\n",
              "      <td>0.142504</td>\n",
              "      <td>0.986047</td>\n",
              "      <td>0.992974</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>85</td>\n",
              "      <td>0.403700</td>\n",
              "      <td>0.146003</td>\n",
              "      <td>0.976744</td>\n",
              "      <td>0.988235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>90</td>\n",
              "      <td>0.442900</td>\n",
              "      <td>0.128453</td>\n",
              "      <td>0.976744</td>\n",
              "      <td>0.988235</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>95</td>\n",
              "      <td>0.322900</td>\n",
              "      <td>0.130469</td>\n",
              "      <td>0.972093</td>\n",
              "      <td>0.985849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.350200</td>\n",
              "      <td>0.133294</td>\n",
              "      <td>0.967442</td>\n",
              "      <td>0.983452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>105</td>\n",
              "      <td>0.331000</td>\n",
              "      <td>0.120087</td>\n",
              "      <td>0.967442</td>\n",
              "      <td>0.983452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>110</td>\n",
              "      <td>0.287100</td>\n",
              "      <td>0.101817</td>\n",
              "      <td>0.967442</td>\n",
              "      <td>0.983452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>115</td>\n",
              "      <td>0.340500</td>\n",
              "      <td>0.097562</td>\n",
              "      <td>0.967442</td>\n",
              "      <td>0.983452</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>120</td>\n",
              "      <td>0.240400</td>\n",
              "      <td>0.087804</td>\n",
              "      <td>0.972093</td>\n",
              "      <td>0.985849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>125</td>\n",
              "      <td>0.387000</td>\n",
              "      <td>0.080744</td>\n",
              "      <td>0.972093</td>\n",
              "      <td>0.985849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>130</td>\n",
              "      <td>0.453300</td>\n",
              "      <td>0.069325</td>\n",
              "      <td>0.972093</td>\n",
              "      <td>0.985849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>135</td>\n",
              "      <td>0.187700</td>\n",
              "      <td>0.074087</td>\n",
              "      <td>0.972093</td>\n",
              "      <td>0.985849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>140</td>\n",
              "      <td>0.132700</td>\n",
              "      <td>0.089528</td>\n",
              "      <td>0.972093</td>\n",
              "      <td>0.985849</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>145</td>\n",
              "      <td>0.243700</td>\n",
              "      <td>0.126758</td>\n",
              "      <td>0.962791</td>\n",
              "      <td>0.981043</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=145, training_loss=0.5934398351044491, metrics={'train_runtime': 498.3199, 'train_samples_per_second': 6.026, 'train_steps_per_second': 0.759, 'total_flos': 9507541682394.0, 'train_loss': 0.5934398351044491, 'epoch': 1.1507936507936507})"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"./best_model_found\")"
      ],
      "metadata": {
        "id": "tRwGn_RsD1vL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579829066,
          "user_tz": 360,
          "elapsed": 1644,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        }
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QstfjqN0c09i",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579833331,
          "user_tz": 360,
          "elapsed": 121,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "0f5f8d20-b852-44bc-812a-5ca114917459"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "best_model_found  model_results  sample_data  wandb\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -lh ./model_results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgoUUR5Qcwiu",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579834893,
          "user_tz": 360,
          "elapsed": 120,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "d1154463-9cb4-4a6f-c440-017b656174bf"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total 8.0K\n",
            "drwxr-xr-x 2 root root 4.0K Oct 16 01:56 checkpoint-130\n",
            "drwxr-xr-x 2 root root 4.0K Oct 16 01:56 checkpoint-145\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls ./best_model_found"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WVSRL9V_F2A2",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579836628,
          "user_tz": 360,
          "elapsed": 193,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "8e93c3e2-a46c-4609-8b9b-db86cb822ae6"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "config.json\t   special_tokens_map.json  tokenizer.json     vocab.txt\n",
            "model.safetensors  tokenizer_config.json    training_args.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the model locally to my machine\n",
        "from google.colab import files\n",
        "\n",
        "!zip -r best_model_found.zip ./best_model_found\n",
        "files.download('best_model_found.zip')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "id": "KsF1rs2UIwvW",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579869032,
          "user_tz": 360,
          "elapsed": 25129,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "963b9f31-5d27-46b2-fa8e-887bf45043eb"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  adding: best_model_found/ (stored 0%)\n",
            "  adding: best_model_found/vocab.txt (deflated 53%)\n",
            "  adding: best_model_found/model.safetensors (deflated 7%)\n",
            "  adding: best_model_found/training_args.bin (deflated 53%)\n",
            "  adding: best_model_found/config.json (deflated 51%)\n",
            "  adding: best_model_found/tokenizer.json (deflated 71%)\n",
            "  adding: best_model_found/tokenizer_config.json (deflated 75%)\n",
            "  adding: best_model_found/special_tokens_map.json (deflated 42%)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7cae35b7-710c-4bfa-9366-28fb4981ba59\", \"best_model_found.zip\", 405570869)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save metrics to wandb\n",
        "import wandb\n",
        "\n",
        "wandb.init(project=\"huggingface\")\n",
        "wandb.save(\".wanddb/*\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 885
        },
        "id": "rnPYiInRADYC",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579875853,
          "user_tz": 360,
          "elapsed": 2219,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "9bb4f5cd-ad79-44d1-b39f-93d4da8963f9"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>▁▅███▇▆███▇██████████████████</td></tr><tr><td>eval/f1</td><td>▁▆███▇▆██████████████████████</td></tr><tr><td>eval/loss</td><td>██▇▆▆▅▅▃▃▃▃▃▂▂▂▁▂▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>eval/runtime</td><td>▂▂█▂▃▂▃▁▂▃██▂▂▂▂▂▄▃▃▄▁▂▂▃▂▃▃▄</td></tr><tr><td>eval/samples_per_second</td><td>▇▇▁▇▆▆▅▇▆▆▁▁▇▆▇▇▇▅▅▅▅█▆▇▅▆▅▅▄</td></tr><tr><td>eval/steps_per_second</td><td>▇▇▁▇▆▆▅▇▆▆▁▁▇▆▇▇▇▅▅▅▅█▆▇▅▆▅▅▄</td></tr><tr><td>train/epoch</td><td>▁▁▁▁▁▂▂▃▃▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇██</td></tr><tr><td>train/global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▆▆▆▆▇▇▇▇▇▇▇▇███</td></tr><tr><td>train/grad_norm</td><td>▂▄▄▄▃▄▃▄▇▃▄▄▃▅▃▃█▄▃▆▂▂▇▃▁█▃▂▁</td></tr><tr><td>train/learning_rate</td><td>▁▂▃▄▅▆▇█████▇▇▇▇▇▇▇▇▆▆▆▆▆▆▆▆▆</td></tr><tr><td>+1</td><td>...</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>eval/accuracy</td><td>0.96279</td></tr><tr><td>eval/f1</td><td>0.98104</td></tr><tr><td>eval/loss</td><td>0.12676</td></tr><tr><td>eval/runtime</td><td>0.4189</td></tr><tr><td>eval/samples_per_second</td><td>513.26</td></tr><tr><td>eval/steps_per_second</td><td>64.456</td></tr><tr><td>total_flos</td><td>9507541682394.0</td></tr><tr><td>train/epoch</td><td>1.15079</td></tr><tr><td>train/global_step</td><td>145</td></tr><tr><td>train/grad_norm</td><td>1.03234</td></tr><tr><td>+6</td><td>...</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">airline-chatbot-model</strong> at: <a href='https://wandb.ai/lanehale1-ai/huggingface/runs/vop2pah9' target=\"_blank\">https://wandb.ai/lanehale1-ai/huggingface/runs/vop2pah9</a><br> View project at: <a href='https://wandb.ai/lanehale1-ai/huggingface' target=\"_blank\">https://wandb.ai/lanehale1-ai/huggingface</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251016_014845-vop2pah9/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.2"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251016_015754-370jq2u0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/lanehale1-ai/huggingface/runs/370jq2u0' target=\"_blank\">different-tree-27</a></strong> to <a href='https://wandb.ai/lanehale1-ai/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/lanehale1-ai/huggingface' target=\"_blank\">https://wandb.ai/lanehale1-ai/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/lanehale1-ai/huggingface/runs/370jq2u0' target=\"_blank\">https://wandb.ai/lanehale1-ai/huggingface/runs/370jq2u0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Symlinked 0 file into the W&B run directory, call wandb.save again to sync new files.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate(tokenized_datasets[\"test\"])\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "0MMEWS33WKKg",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579894130,
          "user_tz": 360,
          "elapsed": 495,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "94cc8e39-9316-4fd0-cec9-7f9261581228"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.04417383670806885,\n",
              " 'eval_accuracy': 0.9953488372093023,\n",
              " 'eval_f1': 0.9976689976689976,\n",
              " 'eval_runtime': 0.4534,\n",
              " 'eval_samples_per_second': 474.218,\n",
              " 'eval_steps_per_second': 59.553,\n",
              " 'epoch': 1.1507936507936507}"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "id": "a09d0861",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579902180,
          "user_tz": 360,
          "elapsed": 720,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "f3d5d2b6-d5c5-497f-cbd9-3b84a8ba48db"
      },
      "source": [
        "# Specify the path to the checkpoint you want to evaluate\n",
        "checkpoint_path = \"./best_model_found\"  # Replace with the actual checkpoint path\n",
        "\n",
        "# Load the model from the checkpoint\n",
        "model_from_checkpoint = AutoModelForSequenceClassification.from_pretrained(\n",
        "    checkpoint_path,\n",
        "    num_labels=3,\n",
        "    problem_type=\"single_label_classification\"\n",
        ")\n",
        "\n",
        "# Create a new Trainer instance with the loaded model\n",
        "trainer_from_checkpoint = Trainer(\n",
        "    model_from_checkpoint,\n",
        "    training_args,  # You can reuse the existing training_args\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "# Evaluate the model from the checkpoint\n",
        "results_from_checkpoint = trainer_from_checkpoint.evaluate(tokenized_datasets[\"test\"])\n",
        "results_from_checkpoint"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='27' max='27' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [27/27 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_loss': 0.04417383670806885,\n",
              " 'eval_model_preparation_time': 0.0026,\n",
              " 'eval_accuracy': 0.9953488372093023,\n",
              " 'eval_f1': 0.9976689976689976,\n",
              " 'eval_runtime': 0.4449,\n",
              " 'eval_samples_per_second': 483.292,\n",
              " 'eval_steps_per_second': 60.693}"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "predictions = trainer.predict(tokenized_datasets[\"test\"])\n",
        "print(predictions.predictions.shape, predictions.label_ids.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "XHLqHQ3pKcnD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579910006,
          "user_tz": 360,
          "elapsed": 453,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "3aaaef14-1e6c-4a74-da29-31e8048bbb1b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(215, 3) (215,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# See predictions, labels, and metrics\n",
        "import numpy as np\n",
        "\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=-1)\n",
        "ground_truth_labels = predictions.label_ids\n",
        "metrics = predictions.metrics\n",
        "\n",
        "print(\"Predicted labels:\", predicted_labels)\n",
        "print(\"Ground truth labels:\", ground_truth_labels)\n",
        "print(\"Metrics:\")\n",
        "metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIvGmPDrL33r",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579937879,
          "user_tz": 360,
          "elapsed": 49,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "2426d818-cc88-4983-f479-03a0af494792"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Ground truth labels: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "Metrics:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_loss': 0.04417383670806885,\n",
              " 'test_accuracy': 0.9953488372093023,\n",
              " 'test_f1': 0.9976689976689976,\n",
              " 'test_runtime': 0.4536,\n",
              " 'test_samples_per_second': 473.954,\n",
              " 'test_steps_per_second': 59.52}"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test model with classification pipeline"
      ],
      "metadata": {
        "id": "TpkcKvQ-ZO0b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a classification pipeline\n",
        "from transformers import pipeline, AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "# Define ID to label mapping\n",
        "id2label_mapping = {0: 'booking', 1: 'general', 2:'status'}\n",
        "\n",
        "model_path = \"./best_model_found\"\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\n",
        "    model_path,\n",
        "    id2label=id2label_mapping\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "question_classifier = pipeline(\"text-classification\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "question = \"How can I book a flight?\"\n",
        "question_classifier(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lS-AyC7PRx5",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579947866,
          "user_tz": 360,
          "elapsed": 426,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "d3972c30-d077-4c0a-a229-01326b239680"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'general', 'score': 0.821153461933136}]"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"When does UA 504 arrive?\"\n",
        "question_classifier(question)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6btwtoqLRxGd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579963317,
          "user_tz": 360,
          "elapsed": 90,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "65d9c58c-0a65-4ece-f260-8e67120e751a"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'status', 'score': 0.9525623321533203}]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_classifier(\"Book me a flight for tomorrow night LAX-SEA\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxj17GqrR4MD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579965291,
          "user_tz": 360,
          "elapsed": 62,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "fcc62866-2ea2-4554-a264-335a177f9dd8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'booking', 'score': 0.9740308523178101}]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_classifier(\"what is my name\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRcIaxqIU7dI",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579967298,
          "user_tz": 360,
          "elapsed": 121,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "c2bbd027-1773-4d6b-a778-b74380d1e1a2"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'general', 'score': 0.4874076843261719}]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_classifier(\"reserve dallas chicago next week\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E39y2I0iVH5o",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579971870,
          "user_tz": 360,
          "elapsed": 44,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "28286f2a-5a7f-45b7-e489-81ed70504b08"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'booking', 'score': 0.9545001983642578}]"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_classifier(\"how late is united 2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBXemRrWVXF4",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760579975519,
          "user_tz": 360,
          "elapsed": 24,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "7ea3195e-60aa-458d-989d-7e13631ab4ed"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'status', 'score': 0.9309108257293701}]"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question_classifier(\"where is my gate?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CC76igNEvr-N",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1760580008593,
          "user_tz": 360,
          "elapsed": 103,
          "user": {
            "displayName": "Lane Hale",
            "userId": "11862511056076326919"
          }
        },
        "outputId": "b90ba1db-b07a-4c3e-cb29-bafd0277f552"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'status', 'score': 0.8358936905860901}]"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    }
  ]
}
